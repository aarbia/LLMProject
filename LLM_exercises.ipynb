{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quUTuNz3-ypx"
   },
   "source": [
    "# Step 1: Setting up our virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uc7NJG709HKh",
    "outputId": "f7ac96eb-2716-4ade-f043-ff5f572fbd78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting uv\n",
      "  Downloading uv-0.6.10-py3-none-win_amd64.whl.metadata (11 kB)\n",
      "Downloading uv-0.6.10-py3-none-win_amd64.whl (17.4 MB)\n",
      "   ---------------------------------------- 0.0/17.4 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 7.3/17.4 MB 75.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 17.4/17.4 MB 68.7 MB/s eta 0:00:00\n",
      "Installing collected packages: uv\n",
      "Successfully installed uv-0.6.10\n"
     ]
    }
   ],
   "source": [
    "!pip install uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLnLvKZh9ZB5",
    "outputId": "3784470d-0bf1-4e70-afe9-8555b2142af2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.10.16 environment at: .pixi\\envs\\default\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m9 packages\u001b[0m \u001b[2min 731ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/requirements.txt --system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0B05a7PX-8xd"
   },
   "source": [
    "# Step 2: Working with text data.\n",
    "Here we will work on tokenizing text and preparing data to use to train our LLM. Taking letters and words and representing them in a way a machine can understand.\n",
    "We will be taking our tokenized text and work on creating token IDs, an middle step before converting to embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4ZZrONXu-oiC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "#download the raw text from the github for this story and save locally as txt file\n",
    "if not os.path.exists(\"the-verdict.txt\"):\n",
    "  url = (\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch02/01_main-chapter-code/the-verdict.txt\")\n",
    "  file_path = \"the-verdict.txt\"\n",
    "  urllib.request.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MGDgq8w0CGmL"
   },
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "  raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "G6kjWAYCCP6d",
    "outputId": "5c392fd8-82af-46ba-c410-05c56a23d542"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather a cheap g'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Si6REa62Cntc",
    "outputId": "f916b7fa-a1a9-41ec-cbb9-8f7cc17bcc66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20479"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Y5E0f_fCrPt",
    "outputId": "89d1a647-ff87-4d91-d16f-51fdc76ee0a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Hello, world. This, is a test.\"\n",
    "result = re.split(r'(\\s)', text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkTORXnzDKfD",
    "outputId": "cc349aa9-cad6-44f1-b9cf-0094d85ab821"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(r'([,.]|\\s)', text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r6nJwjwbDVo4",
    "outputId": "faf98093-6c85-47a4-f46e-79ff187cbf97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
     ]
    }
   ],
   "source": [
    "result = [item for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GRHD7BXyDpxF",
    "outputId": "876f8436-b005-4c5e-f977-b9f18d5af4fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world. Is this-- a test?\"\n",
    "\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result[:30])\n",
    "preprocessed = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4t4RHDmkEALI",
    "outputId": "33b20bd8-0218-4232-aebf-5c59ee2db579"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4690"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucpEKQxp-r_-"
   },
   "source": [
    "##Converting tokens to token IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2GyfpStGEWv4",
    "outputId": "53290505-2c2d-41e9-f7b8-c5fcc021ee6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6CXxdDIOEzbh",
    "outputId": "c738b56c-3748-48e1-c5be-45e2f5c54cd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n",
      "('Burlington', 21)\n",
      "('But', 22)\n",
      "('By', 23)\n",
      "('Carlo', 24)\n",
      "('Chicago', 25)\n",
      "('Claude', 26)\n",
      "('Come', 27)\n",
      "('Croft', 28)\n",
      "('Destroyed', 29)\n",
      "('Devonshire', 30)\n",
      "('Don', 31)\n",
      "('Dubarry', 32)\n",
      "('Emperors', 33)\n",
      "('Florence', 34)\n",
      "('For', 35)\n",
      "('Gallery', 36)\n",
      "('Gideon', 37)\n",
      "('Gisburn', 38)\n",
      "('Gisburns', 39)\n",
      "('Grafton', 40)\n",
      "('Greek', 41)\n",
      "('Grindle', 42)\n",
      "('Grindles', 43)\n",
      "('HAD', 44)\n",
      "('Had', 45)\n",
      "('Hang', 46)\n",
      "('Has', 47)\n",
      "('He', 48)\n",
      "('Her', 49)\n",
      "('Hermia', 50)\n"
     ]
    }
   ],
   "source": [
    "vocab = {token:integer for integer,token in enumerate(all_words)}\n",
    "\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WgQMyAeQFHdf"
   },
   "outputs": [],
   "source": [
    "#this class will take our tokenizing practice above and put it into practice for us\n",
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "\n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5Iekk6jHIYo",
    "outputId": "c1e0c2d1-907e-47a9-a2fd-db67ccc235f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"\"\"\"It's the last he painted, you know,\"\n",
    "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "d9120GylJMnR",
    "outputId": "08ac3fa3-a8e2-4467-f693-0752b67681b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "-Qeydk92JND6",
    "outputId": "66f93b3d-2972-4f56-bedd-4b7216404e78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktbcfQzFKlhF"
   },
   "source": [
    "## Adding Special tokens:\n",
    "Some tokenizers use special tokens to help the LLM with additional context\n",
    "Examples:\n",
    "\n",
    "*    [BOS] (beginning of sequence) marks the beginning of text\n",
    "*    [EOS] (end of sequence) marks where the text ends (this is usually used to concatenate multiple unrelated texts, e.g., two different Wikipedia articles or two different books, and so on)\n",
    "*    [PAD] (padding) if we train LLMs with a batch size greater than 1 (we may include multiple texts with different lengths; with the padding token we pad the shorter texts to the longest length so that all texts have an equal length)\n",
    "*    [UNK] to represent words that are not included in the vocabulary\n",
    "\n",
    "Note that GPT-2 does not need any of these tokens mentioned above but only uses an <|endoftext|> token to reduce complexity\n",
    "\n",
    "The <|endoftext|> is analogous to the [EOS] token mentioned above\n",
    "\n",
    "GPT also uses the <|endoftext|> for padding (since we typically use a mask when training on batched inputs, we would not attend padded tokens anyways, so it does not matter what these tokens are)\n",
    "\n",
    "GPT-2 does not use an <UNK> token for out-of-vocabulary words; instead, GPT-2 uses a byte-pair encoding (BPE) tokenizer, which breaks down words into subword units which we will discuss in a later section\n",
    "\n",
    "**We use the <|endoftext|> tokens between two independent sources of text:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "DmDiE_KVLxc5"
   },
   "outputs": [],
   "source": [
    "#tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "#text = \"Hello, do you like tea. Is this-- a test?\"\n",
    "\n",
    "#tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PtvkPcuAL5o6"
   },
   "outputs": [],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1H-VY3y2L9qi",
    "outputId": "08024a5a-80a1-46b7-c7f5-bd854bb328e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|endoftext|>', 1130)\n",
      "('<|unk|>', 1131)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "yM2qBt0VMC-k"
   },
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int\n",
    "            else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24d31cTGMQtP",
    "outputId": "a9fb48bd-18ec-4ca3-8831-20ae626ffcde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DyUeHElhMWaq",
    "outputId": "cfc36065-71df-44d4-df3c-d79c18a1eb21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "q2LeVaJtMalk",
    "outputId": "da826bcf-ef00-4b00-d287-8aed84f1aa58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07mRS-GJMzz3"
   },
   "source": [
    "## Byte pair encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "vAj25LVSM2ow"
   },
   "outputs": [],
   "source": [
    " import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "qlX-E1_DSj1_"
   },
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTS_wvRcStww",
    "outputId": "c069532f-0fc0-4d91-956f-14ed864f2688"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15496, 995]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "dyHYB-sTS2Cp",
    "outputId": "9910e78c-e307-4cfc-8e3f-33fe5c5c83d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello world'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(\"Hello world\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BE6xEDQZS8f5",
    "outputId": "0018f03c-8dac-4489-8238-d4ba0c8518df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\"\n",
    ")\n",
    "\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oCZ_knQ7TJ_E",
    "outputId": "39b0e8e5-1d71-4ca1-ae1b-0c412c6c2562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r55F72XjTbmr"
   },
   "source": [
    "## Data Sampling: teaching out LLM to predict one word at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQwcJ1PnTTF8",
    "outputId": "befb9ec1-4ebe-4357-cd66-0773201c9ad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "E9jKR5KyUGyD"
   },
   "outputs": [],
   "source": [
    "enc_sample = enc_text[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XuG1DAbJUcTB",
    "outputId": "a5dc1df1-ef13-4514-e3f6-a403f07147f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y:      [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4\n",
    "\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_lsFkEpUf9E",
    "outputId": "a1d60e56-2a18-4e10-b823-1dfdf8ef0f76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] ----> 4920\n",
      "[290, 4920] ----> 2241\n",
      "[290, 4920, 2241] ----> 287\n",
      "[290, 4920, 2241, 287] ----> 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "\n",
    "    print(context, \"---->\", desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPNupS0oUneK",
    "outputId": "8aaf81e7-6397-4438-af4d-3e407d80cb47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "kgDeR6FpVAVr"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Gbg6QCp0VNmA"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "iiYpjrlLZpex"
   },
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "PPCKDb-0Zuw6"
   },
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XHtVkjefZxzm",
    "outputId": "fdc5f14e-76d2-4312-c54c-3c7e67ea128b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vO-t1qlMZyIo",
    "outputId": "997dc4dc-6c7c-41ad-b47b-9a301d49e6bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwULANJ-aAXG",
    "outputId": "564f8f72-7241-4458-abae-44877647269a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkNNWY9IeXhd"
   },
   "source": [
    "## Creating token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "wE5Xr4V6eZ3c"
   },
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "4Nw4-B3oevQL"
   },
   "outputs": [],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ulD0E7TifD8z",
    "outputId": "01e0abad-63fc-43d2-f8c8-5f97866020d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ewrJEiHpfbcl",
    "outputId": "0ea125d5-331f-4e68-f177-b201b96510b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hi00rc-Yfic8",
    "outputId": "b184b505-695d-4932-e50f-c87e2659e940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMBzFvdAgg4d"
   },
   "source": [
    "## Encoding word positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "ATxyfZWkf8mR"
   },
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "bkaV1pg0g-cq"
   },
   "outputs": [],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8vYDChOEhBxz",
    "outputId": "567e6e3b-c7a4-4f15-a241-071c04a2a3c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rWdQXhvjhE2a",
    "outputId": "880d2edb-68d5-4240-d3d3-6dab581d8021"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)\n",
    "#print(token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uaYIzTcUhNbM",
    "outputId": "ca4b91c6-b840-4d0f-855e-bcc446a9a7fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.7375, -0.5620, -0.6303,  ..., -0.2277,  1.5748,  1.0345],\n",
      "        [ 1.6423, -0.7201,  0.2062,  ...,  0.4118,  0.1498, -0.4628],\n",
      "        [-0.4651, -0.7757,  0.5806,  ...,  1.4335, -0.4963,  0.8579],\n",
      "        [-0.6754, -0.4628,  1.4323,  ...,  0.8139, -0.7088,  0.4827]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "\n",
    "print(pos_embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dh7Qi4BlhYqq",
    "outputId": "cc282eea-51db-4d72-e19a-738192fbfa1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n",
      "tensor([[ 1.7375, -0.5620, -0.6303,  ..., -0.2277,  1.5748,  1.0345],\n",
      "        [ 1.6423, -0.7201,  0.2062,  ...,  0.4118,  0.1498, -0.4628],\n",
      "        [-0.4651, -0.7757,  0.5806,  ...,  1.4335, -0.4963,  0.8579],\n",
      "        [-0.6754, -0.4628,  1.4323,  ...,  0.8139, -0.7088,  0.4827]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeddings.shape)\n",
    "\n",
    "print(pos_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u2QbjCgPiwEp",
    "outputId": "128f162f-c3e2-4b8e-b201-746ca1ace29f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFqNQUqbKook"
   },
   "source": [
    "# Step 3: coding attention mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iXUXAnPs3-Lm",
    "outputId": "2351a295-dd5d-4129-c26f-af53261a1850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\"torch version:\", version(\"torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "7zzl3l-Q536W"
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gBV54BNv6Lrw",
    "outputId": "a06e58e5-b014-4f4d-8ce2-0f632207224b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]  # 2nd input token is the query\n",
    "\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query) # dot product (transpose not necessary here since they are 1-dim vectors)\n",
    "\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gm08QxJ76IG2",
    "outputId": "ea048670-b49e-43b2-a199-267e0decb639"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9544)\n",
      "tensor(0.9544)\n"
     ]
    }
   ],
   "source": [
    "res = 0.\n",
    "\n",
    "for idx, element in enumerate(inputs[0]):\n",
    "    res += inputs[0][idx] * query[idx]\n",
    "\n",
    "print(res)\n",
    "\n",
    "#alternatively to simplify:\n",
    "print(torch.dot(inputs[0], query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_7HnQ0rA_Pwc",
    "outputId": "3bfa4831-5558-4dfb-86d9-7a3e80008786"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
    "attn_weights_2_tmp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8Uo8_v7_rVd",
    "outputId": "6ea3a9e0-2798-4715-842f-afa20992fb05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax_native(x):\n",
    "  return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "\n",
    "softmax_native(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xO4nehs4ADWT",
    "outputId": "8bef706c-af48-4d2c-e1f5-6db18d5f8e36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "#pytorch function reccomended\n",
    "\n",
    "print(\"Attention weights:\", attn_weights_2)\n",
    "print(\"Sum:\", attn_weights_2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDEvC2XnARCz",
    "outputId": "cc76a5e4-989f-40bc-d5e8-769e719a6434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13854756951332092 ---> tensor([0.4300, 0.1500, 0.8900])\n",
      "0.2378913015127182 ---> tensor([0.5500, 0.8700, 0.6600])\n",
      "0.23327402770519257 ---> tensor([0.5700, 0.8500, 0.6400])\n",
      "0.12399158626794815 ---> tensor([0.2200, 0.5800, 0.3300])\n",
      "0.10818186402320862 ---> tensor([0.7700, 0.2500, 0.1000])\n",
      "0.15811361372470856 ---> tensor([0.0500, 0.8000, 0.5500])\n",
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1] # 2nd input token is the query\n",
    "\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i,x_i in enumerate(inputs):\n",
    "  print(f\"{attn_weights_2[i]} ---> {inputs[i]}\")\n",
    "  context_vec_2 += attn_weights_2[i]*x_i\n",
    "\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vaS10DkA5_n"
   },
   "source": [
    "## Computing attention weights for all input tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W3wWp5vWAv1_",
    "outputId": "968583fa-2d33-4623-926c-bc218b82218d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = torch.empty(6, 6) #create 6x6 attn score matrix!\n",
    "\n",
    "for i, x_i in enumerate(inputs):\n",
    "  for j, x_j in enumerate(inputs):\n",
    "    attn_scores[i, j] = torch.dot(x_i, x_j)\n",
    "\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ODlRL2nahHhE",
    "outputId": "d7a0b3c7-5d8a-432e-fec7-728f4f9cb8bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "#matrix multiplication to avoid for loops\n",
    "attn_scores = inputs @ inputs.T\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l48AclUEhRm4",
    "outputId": "8ed561ec-96e7-47bb-d703-634261b76f77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
     ]
    }
   ],
   "source": [
    "#normalize each row so that the values in each row sum to 1\n",
    "attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zpv4VifGhyqy",
    "outputId": "d998e877-8220-4e37-d3a0-b8eaf4c61e4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2 sum: 1.0\n",
      "All row sums: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "#Quick verification that the values in each row indeed sum to 1:\n",
    "row_2_sum = sum([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
    "print(\"Row 2 sum:\", row_2_sum)\n",
    "\n",
    "print(\"All row sums:\", attn_weights.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KsGzU-aGiDTi",
    "outputId": "3e416325-1ec0-407d-b1c1-eb4ec7be6411"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "#compute all context vectors\n",
    "all_context_vecs = attn_weights @ inputs\n",
    "print(all_context_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CjHnyy_iQ7p",
    "outputId": "713ba9f5-e884-4443-fe98-2147c0718f0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous 2nd context vector: tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "print(\"Previous 2nd context vector:\", context_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4YwORq1idf3"
   },
   "source": [
    "## Implementing self attention with trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "nUO-3Yd1ikMj"
   },
   "outputs": [],
   "source": [
    "x_2 = inputs[1] # second input element\n",
    "d_in = inputs.shape[1] # the input embedding size, d=3\n",
    "d_out = 2 # the output embedding size, d=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "pJV9yWjakspG"
   },
   "outputs": [],
   "source": [
    "#initialize the three weight matrices,  for model training, we would set requires_grad=True to update these matrices during model training\n",
    "torch.manual_seed(123)\n",
    "\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key   = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OcfaITqIlNzA",
    "outputId": "de55451d-66c5-4176-880f-2bb54a1a2190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n"
     ]
    }
   ],
   "source": [
    "#compute the query, key, and value vectors\n",
    "query_2 = x_2 @ W_query # _2 because it's with respect to the 2nd input element\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "\n",
    "print(query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tAp7JbUeliBU",
    "outputId": "7bd867f1-2b65-4621-ebdb-4c8147d24922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.3669, 0.7646],\n",
       "        [0.4433, 1.1419],\n",
       "        [0.4361, 1.1156],\n",
       "        [0.2408, 0.6706],\n",
       "        [0.1827, 0.3292],\n",
       "        [0.3275, 0.9642]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fH23j0BQmgnb",
    "outputId": "0b1b978e-b809-432d-e5d8-fd2d126e0c26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8524)\n"
     ]
    }
   ],
   "source": [
    "#we compute the unnormalized attention scores by computing the dot product between the query and each key vector:\n",
    "keys_2 = keys[1] # Python starts index at 0\n",
    "attn_score_22 = query_2.dot(keys_2)\n",
    "print(attn_score_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2tmXtb2p9Vy",
    "outputId": "11c15bc3-5e88-4015-b938-8da7ef24bb21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
     ]
    }
   ],
   "source": [
    "#Since we have 6 inputs, we have 6 attention scores for the given query vector:\n",
    "attn_scores_2 = query_2 @ keys.T # All attention scores for given query\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_JpRhKMqB6w",
    "outputId": "6fa07d8b-7f2a-4a70-c69e-cdc51f738a19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
     ]
    }
   ],
   "source": [
    "#we compute the attention weights (normalized attention scores that sum up to 1)\n",
    "d_k = keys.shape[1]\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
    "print(attn_weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cig1VFJgqxrN",
    "outputId": "32e61f6d-b220-4b2c-df38-39804ec7980b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "source": [
    "#we now compute the context vector for input query vector 2:\n",
    "context_vec_2 = attn_weights_2 @ values\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQG_naTPq5dg"
   },
   "source": [
    "## Implementing a Self Attention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ovBxNjYpq_67",
    "outputId": "8ee2c848-d1e5-4dc2-8cc8-0788cc3aadad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "\n",
    "        attn_scores = queries @ keys.T # omega\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMm5wYFCrN07",
    "outputId": "d8a7fc6e-9325-408c-dbb8-f1b09426c93d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#we can silplify this with pytorch funtions\n",
    "\n",
    "class SelfAttention_v2(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKRsH-zctZrM"
   },
   "source": [
    "## Hiding words with casual attention\n",
    "Causal self-attention ensures that the model's prediction for a certain position in a sequence is only dependent on the known outputs at previous positions, not on future positions\n",
    "To achieve this, for each given token, we mask out the future tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ffgSfRmt3hM",
    "outputId": "e64603ee-8af0-44a0-b4f9-cea4578386d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
      "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
      "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa_v2.W_query(inputs)\n",
    "keys = sa_v2.W_key(inputs)\n",
    "values = sa_v2.W_value(inputs)\n",
    "\n",
    "attn_scores = queries @ keys.T\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rhfOUywtu-R5",
    "outputId": "42d74d6f-e375-499b-945d-cc097f4291bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#The simplest way to mask out future attention weights is by creating a mask via\n",
    "#PyTorch's tril function with elements below the main diagonal (including the diagonal\n",
    "#itself) set to 1 and above the main diagonal set to 0:context_length = attn_scores.shape[0]\n",
    "\n",
    "context_length = attn_scores.shape[0]\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "print(mask_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQl6qm5cvEyJ",
    "outputId": "7ced1c8a-ad88-4496-d196-3d9ad82c9d08",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "masked_simple = attn_weights*mask_simple\n",
    "print(masked_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YRI-_mxyvYjB",
    "outputId": "529145ef-a844-45b7-bbec-51d7cad2a337",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#To make sure that the rows sum to 1, we can normalize the attention weights as follows:\n",
    "\n",
    "row_sums = masked_simple.sum(dim=-1, keepdim=True)\n",
    "masked_simple_norm = masked_simple / row_sums\n",
    "print(masked_simple_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEmzwO_vvd2I",
    "outputId": "0020578a-fb83-4403-d931-769ad96c8af2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#alternativvely, we can mask before normalizing the weights to simplify\n",
    "\n",
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "print(masked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgVq3Kx5v8Qc",
    "outputId": "c944b610-bcea-46d8-c45e-aec15e89905a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cwbf1zQ4wyX1"
   },
   "source": [
    "## dropout masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TwxngeCHwAOK",
    "outputId": "c1c4e485-f529-4748-dee8-b7c89e854a8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2., 2., 2., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 2., 0.],\n",
      "        [2., 2., 0., 0., 0., 2.],\n",
      "        [2., 0., 0., 0., 0., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5) # dropout rate of 50%\n",
    "example = torch.ones(6, 6) # create a matrix of ones\n",
    "\n",
    "print(dropout(example))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4X6VcxEx_7y",
    "outputId": "a117625b-1c63-4529-a5ed-20ef9b6e3908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.8966, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6206, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4921, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4350, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3327, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQHMRUXjyB5x"
   },
   "source": [
    "## Implementing a compact self attention class with masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6TjWFs-yM5q",
    "outputId": "5a9f44b8-49c5-4fa5-a6b2-7c7b82f30523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape) # 2 inputs with 6 tokens each, and each token has embedding dimension 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RjsjtY3yY0A",
    "outputId": "cc1d3474-6b2d-4ae8-ad2b-3bff941f93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]],\n",
      "\n",
      "        [[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length,\n",
    "                 dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout) # New\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1)) # New\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape # New batch dimension b\n",
    "        # For inputs where `num_tokens` exceeds `context_length`, this will result in errors\n",
    "        # in the mask creation further below.\n",
    "        # In practice, this is not a problem since the LLM (chapters 4-7) ensures that inputs\n",
    "        # do not exceed `context_length` before reaching this forward method.\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1, 2) # Changed transpose\n",
    "        attn_scores.masked_fill_(  # New, _ ops are in-place\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)  # `:num_tokens` to account for cases where the number of tokens in the batch is smaller than the supported context_size\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        attn_weights = self.dropout(attn_weights) # New\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "context_length = batch.shape[1]\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "\n",
    "context_vecs = ca(batch)\n",
    "\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUAVoYUazmWE"
   },
   "source": [
    "## Stacking multiple single-head attention layers\n",
    "The main idea behind multi-head attention is to run the attention mechanism multiple times (in parallel) with different, learned linear projections. This allows the model to jointly attend to information from different representation subspaces at different positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0zt6bpn0JIN",
    "outputId": "c6b8fc4e-a34d-4003-a100-d688450af727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias)\n",
    "             for _ in range(num_heads)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "context_length = batch.shape[1] # This is the number of tokens\n",
    "d_in, d_out = 3, 2\n",
    "mha = MultiHeadAttentionWrapper(\n",
    "    d_in, d_out, context_length, 0.0, num_heads=2\n",
    ")\n",
    "\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7w_nOTqn3IXp"
   },
   "source": [
    "## Multihead attention with split weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gi6NqZBP3UW0",
    "outputId": "79f72574-8dfc-4ca9-e186-ef3cf09d82d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]],\n",
      "\n",
      "        [[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        # As in `CausalAttention`, for inputs where `num_tokens` exceeds `context_length`,\n",
    "        # this will result in errors in the mask creation further below.\n",
    "        # In practice, this is not a problem since the LLM (chapters 4-7) ensures that inputs\n",
    "        # do not exceed `context_length` before reaching this forwar\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kH8vS-CIQF4b"
   },
   "source": [
    "# Step 4: Implementing a GPT model to generate text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJ0HGzvQQ96L"
   },
   "source": [
    "*   We use short variable names to avoid long lines of code later\n",
    "*   \"vocab_size\" indicates a vocabulary size of 50,257 words, supported by the BPE tokenizer discussed in Chapter 2\n",
    "*   \"context_length\" represents the model's maximum input token count, as enabled by positional embeddings covered in Chapter 2\n",
    "*   \"emb_dim\" is the embedding size for token inputs, converting each input token into a 768-dimensional vector\n",
    "*   \"n_heads\" is the number of attention heads in the multi-head attention mechanism implemented in Chapter 3\n",
    "*   \"n_layers\" is the number of transformer blocks within the model, which we'll implement in upcoming sections\n",
    "*   \"drop_rate\" is the dropout mechanism's intensity, discussed in Chapter 3; 0.1 means dropping 10% of hidden units during training to mitigate overfitting\n",
    "*   \"qkv_bias\" decides if the Linear layers in the multi-head attention mechanism (from Chapter 3) should include a bias vector when computing query (Q), key (K), and value (V) tensors; we'll disable this option, which is standard practice in modern LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "QVek1HdWQNr6"
   },
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "naBJNdzCQ0M9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        # Use a placeholder for TransformerBlock\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        # Use a placeholder for LayerNorm\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # A simple placeholder\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This block does nothing and just returns its input.\n",
    "        return x\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # The parameters here are just to mimic the LayerNorm interface.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This layer does nothing and just returns its input.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RIZuD8mMdP9j",
    "outputId": "b73bcc89-493b-4bc6-d342-40883cc9368a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9BaLbpQFdGxf",
    "outputId": "0104ffea-e774-42bf-cd9e-df80c50b330d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
      "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
      "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
      "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
      "\n",
      "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
      "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
      "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
      "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDCGT8HsenNH"
   },
   "source": [
    "## normalizing activations with layer normalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aMikjz-Rdop6",
    "outputId": "90359d53-c687-4d7d-8cd3-144d60240b9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969],\n",
       "        [ 0.2093, -0.9724, -0.7550,  0.3239, -0.1085]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "# create 2 training examples with 5 dimensions (features) each\n",
    "batch_example = torch.randn(2, 5)\n",
    "batch_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HtXzrn0MfTZg",
    "outputId": "676a06c6-1230-4090-eec3-658f11742dcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bF7wz1BCgR-i",
    "outputId": "f012f216-8b23-4cf6-82b2-7847f5040896"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1324],\n",
       "        [0.2170]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5yhktp5r0iX",
    "outputId": "9abcfff5-1838-4a13-aeb3-f398c7fa62fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0231],\n",
       "        [0.0398]], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = out.var(dim=-1, keepdim=True)\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eFOutoawr4uX",
    "outputId": "b150e9d2-610e-4ec4-e47b-1c598f96dfb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[9.9341e-09],\n",
      "        [0.0000e+00]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "WP1xQ-kSsQSc"
   },
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "s1SU3DxxsgPH"
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "# The initial scale (multiplying by 1) and shift (adding 0) values don't\n",
    "# have any effect; however, scale and shift are trainable parameters that the\n",
    "# LLM automatically adjusts during training if it is determined that doing so\n",
    "# would improve the model's performance on its training task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "ien6kF2atlid"
   },
   "outputs": [],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zoyA5FPBt-Nl",
    "outputId": "eec719ed-48d1-4ce8-fb0f-c8812a020689"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUNDLD_UuzRn"
   },
   "source": [
    "## Implementing a feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "Mym8dHGCv3Xb"
   },
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "NHq3oS9UyEVH",
    "outputId": "014d1950-0050-49bb-8c35-8d3835554fd9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAEiCAYAAABkykQ1AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAa0tJREFUeJzt3XlYVOXbB/DvMMCwyCI7KAhuuCuCJuZuYqKltrkvpf7CrRJNRSuXFit9y8q9TFPS3DIrl6AStNQExBV3ERRBQWSHYZbz/kFMjoAybGdm+H6ua66aM+ecuW8G5+E+51kkgiAIICIiIiIiqgYTsQMgIiIiIiLDx8KCiIiIiIiqjYUFERERERFVGwsLIiIiIiKqNhYWRERERERUbSwsiIiIiIio2lhYEBERERFRtbGwICIiIiKiamNhQURERERE1cbCoh46e/YsJk2ahGbNmsHS0hKWlpZo0aIFXn/9dcTGxmrtu3jxYkgkkgofN2/e1OwrkUgwY8aMCt+3T58+aNeuXbmvZWRkQCKRYPHixTWRYqWtWbMGmzdvLrP95s2bkEgk5b5WUxISErB48WKtn2GpiRMnwtvbu9be+3Fu3ryJwYMHw8HBARKJBG+99ZYocQBAQUEBFi9ejKioqDKvbd68uczvIBFVXem/qdKHqakp3N3dMXLkSFy9erVK54yKioJEIsHu3bsr3Odxbcfu3bshkUjK/Q6oLWJ/7xw4cKDCttDb2xsTJ06stfd+nD/++AMBAQGwtraGRCLBTz/9JEocgP62nwSYih0A1a3169djxowZ8PX1xZtvvom2bdtCIpHg4sWL2L59O7p06YJr166hWbNmWscdOnQIdnZ2Zc7n7u5eV6HXijVr1sDJyanMF7W7uzuOHz9e5udQkxISErBkyRL06dOnzJfgu+++izfffLPW3vtxZs2ahX/++Qfffvst3NzcRP2MCwoKsGTJEgAlhenDBg8ejOPHjxv87yCRvtm0aRNatWqFoqIi/P333/jwww9x+PBhXLp0CQ0bNhQ7vFon9vfOgQMHsHr16nKLi71798LW1rbW3rsigiDglVdeQcuWLfHzzz/D2toavr6+dR5HKX1tP4mFRb3y999/Y9q0aRg8eDB2794Nc3NzzWv9+vXD9OnTsWvXLlhaWpY51t/fH05OTnUZrqhkMhm6desm2vvXZkHzJOfPn0fXrl0xbNgw0WKoDGdnZzg7O4sdBpHRadeuHQICAgCU/GGtUqmwaNEi/PTTT3j11VdFjk5cYn/v+Pn5ifK+d+7cQWZmJoYPH47+/fuLEkNlidl+ErtC1SsfffQRpFIp1q9fr1VUPOzll1+Gh4dHHUdWeUVFRZg9ezY6deoEOzs7ODg4IDAwEPv27Suzr1qtxldffYVOnTrB0tIS9vb26NatG37++WcAJbeUL1y4gOjoaM2t/9IrH492hfrpp58gkUjwxx9/lHmftWvXQiKR4OzZswCA2NhYjBw5Et7e3rC0tIS3tzdGjRqFpKQkzTGbN2/Gyy+/DADo27ev5v1L36+8W7lFRUUICwuDj48PzM3N0ahRI0yfPh1ZWVla+3l7e2PIkCE4dOgQOnfuDEtLS7Rq1QrffvvtY3+2pV0Wrl27hoMHD2p1d6vo9n/pMQ93GSjt8hYTE4OePXvCysoKTZs2xccffwy1Wq11fFZWFmbPno2mTZtCJpPBxcUFwcHBuHTpEm7evKlpwJcsWaKJp/TuUkUxffvtt+jYsSMsLCzg4OCA4cOH4+LFi1r7TJw4EQ0aNMC1a9cQHByMBg0awNPTE7Nnz4ZcLn/sz4moviktMu7evau1PTY2Fs8//zwcHBxgYWEBPz8/7Ny5U4wQce3aNbz66qto0aIFrKys0KhRIzz33HM4d+5cmX1r8nvnrbfegrW1NXJycsq8z4gRI+Dq6gqFQgEA2LFjB4KCguDu7g5LS0u0bt0a8+fPR35+vuaYiRMnYvXq1QBQbrfj8rpCJScnY+zYsXBxcYFMJkPr1q3xf//3f1rft6Vt2ooVK/DZZ5/Bx8cHDRo0QGBgIE6cOPHYn+3ixYvRuHFjAMC8efO02sqKuh2VdqN+WGmXt61bt6J169awsrJCx44d8euvv5Y5/tKlSxg1ahRcXV0hk8ng5eWF8ePHQy6X62X7Sf/hHYt6QqVS4fDhwwgICKjSLVyVSgWlUqm1TSKRQCqV1lSIlSKXy5GZmYk5c+agUaNGKC4uxu+//44XXngBmzZtwvjx4zX7Tpw4EeHh4Zg0aRKWLl0Kc3NznDp1SvMFvXfvXrz00kuws7PDmjVrAJTcqSjPkCFD4OLigk2bNpW5WrN582Z07twZHTp0AFDyBe7r64uRI0fCwcEBqampWLt2Lbp06YKEhAQ4OTlh8ODB+Oijj7BgwQKsXr0anTt3BlDxlRZBEDBs2DD88ccfCAsLQ8+ePXH27FksWrQIx48fx/Hjx7ViP3PmDGbPno358+fD1dUV33zzDSZNmoTmzZujV69e5b5H586dcfz4cQwfPhzNmjXDihUrAFStu1taWhrGjBmD2bNnY9GiRdi7dy/CwsLg4eGh+Yxyc3PRo0cP3Lx5E/PmzcNTTz2FvLw8HDlyBKmpqejevTsOHTqEZ599FpMmTcLkyZMB4LFXC5ctW4YFCxZg1KhRWLZsGe7fv4/FixcjMDAQMTExaNGihWZfhUKB559/HpMmTcLs2bNx5MgRvP/++7Czs8N7772nc85ExioxMREA0LJlS822w4cP49lnn8VTTz2FdevWwc7ODj/88ANGjBiBgoKCOh8HcOfOHTg6OuLjjz+Gs7MzMjMz8d133+Gpp55CfHy8pttOTX/vvPbaa/jiiy+wc+dOzb5ASfGyb98+TJ8+HWZmZgCAq1evIjg4WFOMXLp0CZ988glOnjyJP//8E0BJN578/Hzs3r0bx48f15yvou/h9PR0dO/eHcXFxXj//ffh7e2NX3/9FXPmzMH169c1bVup1atXo1WrVli5cqXm/YKDg5GYmFhud2cAmDx5Mjp27IgXXngBM2fOxOjRoytsK59k//79iImJwdKlS9GgQQN8+umnGD58OC5fvoymTZsCKGm/evToAScnJyxduhQtWrRAamoqfv75ZxQXF+tl+0kPEaheSEtLEwAII0eOLPOaUqkUFAqF5qFWqzWvLVq0SABQ7qNZs2Za5wEgTJ8+vcIYevfuLbRt27bc19LT0wUAwqJFi3TKqzT2SZMmCX5+fprtR44cEQAICxcufOzxbdu2FXr37l1me2JiogBA2LRpk2ZbaGioYGlpKWRlZWm2JSQkCACEr7766rEx5uXlCdbW1sIXX3yh2b5r1y4BgHD48OEyx0yYMEFo0qSJ5vmhQ4cEAMKnn36qtd+OHTsEAMKGDRs025o0aSJYWFgISUlJmm2FhYWCg4OD8Prrr1cY58PHDx48WGvbpk2bBABCYmKi1vbDhw+XyaF3794CAOGff/7R2rdNmzbCwIEDNc+XLl0qABAiIyMrjOVxvxePxvTgwQPB0tJSCA4O1tovOTlZkMlkwujRozXbJkyYIAAQdu7cqbVvcHCw4OvrW2E8RMas9N/UiRMnBIVCIeTm5gqHDh0S3NzchF69egkKhUKzb6tWrQQ/Pz+tbYIgCEOGDBHc3d0FlUolCMJ/3xG7du2q8H0f13Y87nvycZRKpVBcXCy0aNFCmDVrlmZ7TX/vCIIgdO7cWejevbvWfmvWrBEACOfOnSv3PdRqtaBQKITo6GgBgHDmzBnNa9OnTxcq+vOsSZMmwoQJEzTP58+fX+737dSpUwWJRCJcvnxZEIT/2rT27dsLSqVSs9/JkycFAML27dvLfb9SpccvX75ca/ujbVWp0r8dHgZAcHV1FXJycjTb0tLSBBMTE2HZsmWabf369RPs7e2Fe/fuVRiPvrafJAjsCkXw9/eHmZmZ5vF///d/Zfb5/fffERMTo/UQa0aIXbt24emnn0aDBg1gamoKMzMzbNy4Uau7y8GDBwEA06dPr7H3fe2111BYWIgdO3Zotm3atAkymQyjR4/WbMvLy8O8efPQvHlzmJqawtTUFA0aNEB+fn6ZLjmVVXo169GrgC+//DKsra3LdNHq1KkTvLy8NM8tLCzQsmVLre5YtcnNzQ1du3bV2tahQwet9z948CBatmyJZ555pkbe8/jx4ygsLCzzM/L09ES/fv3K/IwkEgmee+65x8ZIVB9169YNZmZmsLGxwbPPPouGDRti3759MDUt6eRw7do1XLp0CWPGjAEAKJVKzSM4OBipqam4fPlyncasVCrx0UcfoU2bNjA3N4epqSnMzc1x9erVMm1DTX7vAMCrr76KY8eOaeW8adMmdOnSRWsmxBs3bmD06NFwc3ODVCqFmZkZevfuDQDVahvatGlT5vt24sSJEARB03aUGjx4sFZPg9I77XX1vde3b1/Y2Nhonru6usLFxUXz/gUFBYiOjsYrr7xSY2NZDK39NHQsLOoJJycnWFpalvsPY9u2bYiJidGMPShPx44dERAQoPWoaOrYipiamkKlUpX7Wmk3q9JbxhX58ccf8corr6BRo0YIDw/H8ePHERMTg9deew1FRUWa/dLT0yGVSuHm5qZTjI/Ttm1bdOnSBZs2bQJQ0j0sPDwcQ4cOhYODg2a/0aNHY9WqVZg8eTJ+++03nDx5EjExMXB2dkZhYWGV3vv+/fswNTUt80UrkUjg5uaG+/fva213dHQscw6ZTFbl99dVZd4/PT1d02+3JpT+DMrrMuDh4VHmZ2RlZQULC4syMT78e0RUH23ZsgUxMTH4888/8frrr+PixYsYNWqU5vXSsRZz5szRuihlZmaGadOmASiZQryypFJptduG0NBQvPvuuxg2bBh++eUX/PPPP4iJiUHHjh1r9XsHAMaMGQOZTKbp45+QkICYmBitge55eXno2bMn/vnnH3zwwQeIiopCTEwMfvzxRwCoVttQ0Xde6esPe/S7ubQLkL60DQ8ePIBKparxtsGQ2k9DxzEW9YRUKkW/fv0QERGB1NRUrS+iNm3aAECtrwfg6uqKmJgYCIJQZlBXSkqKZp/HCQ8Ph4+PD3bs2KF1jkcH3Do7O0OlUiEtLa1GpwV89dVXMW3aNFy8eBE3btxAamqqVuORnZ2NX3/9FYsWLcL8+fO14svMzKzy+zo6OkKpVCI9PV3ry1EQBKSlpaFLly5VPndllP4B/ujPWZc/Hh7l7OyM27dvVyuuh5U2BqmpqWVeu3PnTr2a1YyoOlq3bq0ZsN23b1+oVCp888032L17N1566SXNv6WwsDC88MIL5Z5Dl6lIXV1dNW3Ao3RpG8aPH4+PPvpIa3tGRgbs7e01z2v6ewcAGjZsiKFDh2LLli344IMPsGnTJlhYWGgVY3/++Sfu3LmDqKgozV0KAGUGD+vK0dGxwu88ALX+vWdhYVHuhBdVbRscHBwglUprvG0Qs/2sb3jHoh4JCwuDSqVCSEiIZpaKuvTMM88gJycHhw4dKvPazp07YWJign79+j32HBKJBObm5lpFRVpaWplZoQYNGgSgZMamx9H1KsSoUaNgYWGBzZs3Y/PmzWjUqBGCgoK04hMEoczAtm+++abMFTldrhSVDhgPDw/X2r5nzx7k5+fX+vR/pTNslM58Vepxd7meZNCgQbhy5UqZW/UP0+VnFBgYCEtLyzI/o9u3b+PPP//U+ykSifTVp59+ioYNG+K9996DWq2Gr68vWrRogTNnzpS5k136eLi7y5M888wzOHz4MNLT07W2C4KAXbt2wdvbG82bN3/sOSQSSZnv3f3795cpWGr6e6fUq6++ijt37uDAgQMIDw/H8OHDtQqa0jbr0RjXr19frffv378/EhIScOrUKa3tW7ZsgUQiQd++fSudQ1V4e3vj3r17WjOGFRcX47fffqvS+SwtLdG7d2/s2rXrscWJIbWf9Q3vWNQjTz/9NFavXo2ZM2eic+fO+N///oe2bdvCxMQEqamp2LNnDwCUu/hOXFxcuTNGtGnTRmv/69evl7vCaps2bTBmzBisWbMGr7zyCubPn48uXbqgsLAQBw4cwNdff42ZM2dqZoWoyJAhQ/Djjz9i2rRpeOmll3Dr1i28//77cHd311oZtmfPnhg3bhw++OAD3L17F0OGDIFMJkN8fDysrKwwc+ZMAED79u3xww8/YMeOHWjatCksLCzQvn37Ct/f3t4ew4cPx+bNm5GVlYU5c+bAxOS/+tzW1ha9evXC8uXL4eTkBG9vb0RHR2Pjxo1ajQwATVeyDRs2wMbGBhYWFvDx8Sn3NuyAAQMwcOBAzJs3Dzk5OXj66ac1s1r4+flh3Lhxj/25VVeXLl3g6+uLOXPmQKlUomHDhti7dy/++uuvKp/zrbfewo4dOzB06FDMnz8fXbt2RWFhIaKjozFkyBBNX9wmTZpg37596N+/PxwcHDQ/10fZ29vj3XffxYIFCzB+/HiMGjUK9+/fx5IlS2BhYYFFixZV4ydAVH81bNgQYWFhmDt3LrZt24axY8di/fr1GDRoEAYOHIiJEyeiUaNGyMzMxMWLF3Hq1Cns2rVL6xwVTWnau3dvvPfee/jll1/w1FNPYf78+WjRogXS0tLw9ddfIyYmplJT2A4ZMgSbN29Gq1at0KFDB8TFxWH58uVlutTU9PdOqaCgIDRu3BjTpk1DWlpamfU+unfvjoYNGyIkJASLFi2CmZkZvv/+e5w5c6bMuUrboE8++QSDBg2CVCpFhw4dyp0mftasWdiyZQsGDx6MpUuXokmTJti/fz/WrFmDqVOnas3kVRtGjBiB9957DyNHjsTbb7+NoqIifPnllxV2bauMzz77DD169ND8PjRv3hx3797Fzz//jPXr18PGxsag2s96R8yR4ySO06dPC6+++qrg4+MjyGQywcLCQmjevLkwfvx44Y8//tDa93GzQuGRmTUet1/p7Bo5OTnC3LlzhRYtWgjm5uaClZWVEBAQIKxbt05rNqrH+fjjjwVvb29BJpMJrVu3Fr7++utyZ6BQqVTC559/LrRr104wNzcX7OzshMDAQOGXX37R7HPz5k0hKChIsLGxEQBoZpIob1aoUhEREZq8rly5Uub127dvCy+++KLQsGFDwcbGRnj22WeF8+fPl5nNQxAEYeXKlYKPj48glUq13q+8mTYKCwuFefPmCU2aNBHMzMwEd3d3YerUqcKDBw+09itvVidBKJmtqbwZsB5V0fFXrlwRgoKCBFtbW8HZ2VmYOXOmsH///nJnhSpv9q/ycnrw4IHw5ptvCl5eXoKZmZng4uIiDB48WLh06ZJmn99//13w8/MTZDKZAEDzM6xopqpvvvlG6NChg+YzHzp0qHDhwoUysVhbW5eJsbzfI6L6ovTfVExMTJnXCgsLBS8vL6FFixaaWYXOnDkjvPLKK4KLi4tgZmYmuLm5Cf369RPWrVunOa50VqiKHqXfHVevXhXGjh0ruLu7C6ampoK9vb0QFBRUpk2qyIMHD4RJkyYJLi4ugpWVldCjRw/h6NGj5X7v1cb3jiAIwoIFCwQAgqenp2ZWrIcdO3ZMCAwMFKysrARnZ2dh8uTJwqlTp8q0NXK5XJg8ebLg7OwsSCQSrfcrrx1JSkoSRo8eLTg6OgpmZmaCr6+vsHz5cq0YKprVSRCESs3I+LjjDxw4IHTq1EmwtLQUmjZtKqxatarCWaHKm/2rvJwSEhKEl19+WXB0dBTMzc0FLy8vYeLEiUJRUZFmH31sP0kQJIIgCLVUsxARERERUT3BMRZERERERFRtLCyIiIiIiKjaWFgQEREREVG1sbAgIiIiIqJqY2FBRERERETVxsKCiIiIiIiqrd4tkKdWq3Hnzh3Y2Nhord5MRFSfCYKA3NxceHh4aC36WN+wjSAi0qZL+1DvCos7d+7A09NT7DCIiPTSrVu3yqxWXJ+wjSAiKl9l2od6V1jY2NgAKPnh2Nra6nSsQqFAREQEgoKCYGZmVhvh1QljyIM56A9jyMMYcgCql0dOTg48PT0135H1VX1vI4whB8A48mAO+sMY8qir9qHeFRalt7ZtbW2r1GhYWVnB1tbWYH+xAOPIgznoD2PIwxhyAGomj/re/ae+txHGkANgHHkwB/1hDHnUVftQfzvSEhERERFRjWFhQURERERE1SZqYbF27Vp06NBBc8s5MDAQBw8efOwx0dHR8Pf3h4WFBZo2bYp169bVUbRERFRX2D4QERkeUQuLxo0b4+OPP0ZsbCxiY2PRr18/DB06FBcuXCh3/8TERAQHB6Nnz56Ij4/HggUL8MYbb2DPnj11HDkREdUmtg9ERIZH1MHbzz33nNbzDz/8EGvXrsWJEyfQtm3bMvuvW7cOXl5eWLlyJQCgdevWiI2NxYoVK/Diiy/WRchERFQH2D4QERkevZkVSqVSYdeuXcjPz0dgYGC5+xw/fhxBQUFa2wYOHIiNGzdCoVCUO8pdLpdDLpdrnufk5AAoGR2vUCh0irF0f12P0zfGkAdz0B/GkIcx5KBWC/jqz6twV1QtD33OvbbaByKi+iI+OQsx6RIE1/L7iF5YnDt3DoGBgSgqKkKDBg2wd+9etGnTptx909LS4OrqqrXN1dUVSqUSGRkZcHd3L3PMsmXLsGTJkjLbIyIiYGVlVaWYIyMjq3ScvjGGPJiD/jCGPAw5h4O3THDotgmcLaSwkEbCVMeOrgUFBbUTWDXUdvsA8OLTo4whB8A48mAO+sPQ80jPlWPGD6dxL1eK1jHJeKWLl07H65K36IWFr68vTp8+jaysLOzZswcTJkxAdHR0hY3Ho3PoCoJQ7vZSYWFhCA0N1TwvXeQjKCioSnOUR0ZGYsCAAQZ99csY8mAO+sMY8jD0HA6eT8Oh42cBAM80UmPQQN3zKP2DWp/UdvsA8OJTRYwhB8A48mAO+sMQ81CpgdUJUtzLlcDVUoBp2nkcOHBep3PocuFJ9MLC3NwczZs3BwAEBAQgJiYGX3zxBdavX19mXzc3N6SlpWltu3fvHkxNTeHo6Fju+WUyGWQyWZntZmZmVf4DojrH6hNjyIM56A9jyMMQczifko25P5Y0EhMDveCHG1XKQx/zru32AeDFp0cZQw6AceTBHPSHIefxwYFLuJ6bDGtzKSb5yvHcs7V74Un0wuJRgiBo3ZZ+WGBgIH755RetbREREQgICDC4D5qIqLrSc+X435ZYFCnU6NXSGfMGtkTEbzfEDqvW1Eb7wItP5TOGHADjyIM56A9Dy+On+BR8dzwZALD8xfZQ3Iyt9QtPok43u2DBAhw9ehQ3b97EuXPnsHDhQkRFRWHMmDEASq4kjR8/XrN/SEgIkpKSEBoaiosXL+Lbb7/Fxo0bMWfOHLFSICIShVypQkh4HO5kF6GpkzW+GuUHU6nxrHnK9oGIqOoS7uRg/o8lXWRn9G2OAW1c6uR9Rb1jcffuXYwbNw6pqamws7NDhw4dcOjQIQwYMAAAkJqaiuTkZM3+Pj4+OHDgAGbNmoXVq1fDw8MDX375JacSJKJ6RRAEvPvTecQlPYCNhSm+nhAAO0szgx1YWB62D0REVZNVUIzXw/+7mz1rQEuoVco6eW9RC4uNGzc+9vXNmzeX2da7d2+cOnWqliIiItJ/m/6+iZ2xt2EiAVaN7oxmzg3EDqnGsX0gItKdSi3grR2ncSuzEJ4OlvhyZCdITSRQq+rm/Y3nvjkRUT1w9Go6PtifAABYENwavVs6ixwRERHpi5W/X0HU5XRYmJlg/dgA2FuZ1+n7s7AgIjIQiRn5mP79KagF4CX/xpjUw0fskIiISE9EXEjDV39eAwAse6E92njoNrNdTWBhQURkAHKKFJj8XQxyipTo7GWPD4e3e+z6DEREVH9cT89D6M4zAICJ3b0x3K+xKHGwsCAi0nMqtYA3t8fjeno+3O0ssG6cP2SmUrHDIiIiPZAnV+L1rXHIkyvR1dsBCwe3Fi0WFhZERHru098u4fDldMhMTbBhXABcbCzEDomIiPSAIAh4e9cZXLuXB1dbGVaN8YOZiFOPs7AgItJjP8WnYH10yaJ3n77UAe0b24kcERER6Yt10Tdw8HwazKQSrB3rL/qFJxYWRER66sytLMzdU7LA0dQ+zTC0UyORIyIiIn1x9Go6lv92CQCw6Lm26OzVUOSIWFgQEemlezlF+N/WWBQr1ejfygVzgnzFDomIiPTErcwCvLE9HmoBeCWgMcY85SV2SABYWBAR6R25UoXXw+NwN0eO5i4NsPLfBY6IiIiKFCpM/T4ODwoU6NDYDkuH6s8sgSwsiIj0iCAIeGfvecQnZ8HWwhRfjw+AjYWZ2GEREZEeEAQBC/eex/mUHDhYm2PtWH9YmOnPLIEsLIiI9MjmYzexK+42TCTAqtGd4eNkLXZIRESkJ8JPJGHPqX/biFF+aGRvKXZIWlhYEBHpib+vZeCD/RcBAAuCW6NXS2eRIyIiIn0Rl5SJJb8kAADmD2qF7s2dRI6oLBYWRER6IPl+AaZvOwWVWsALnRthUg8fsUMiIiI9cS+nCFPDT0GpFjC4gzum9GwqdkjlYmFBRCSyfLkSU7bEIqtAgY6N7fDR8PZ6MxCPiIjEVaxUY9r3p3AvV46Wrg3w6Ysd9LaNYGFBRCQitVpA6M7TuHw3F842MqwfF6BXA/GIiEhcH+5PQGzSA9jITLF+XACsZaZih1QhFhZERCL66s9r+O3CXZhLTbBurD/c7MRdNZWIiPTHj6du47vjSQCAz0d00vsJPVhYEBGJJOJCGj7//QoA4INh7eDfRPxVU4mISD+cT8lG2I/nAABv9G+BZ9q4ihzRk7GwICISwZW7uZi14zQAYGJ3b7zSxVPcgIiISG88yC9GSHgc5Eo1+vg6463+LcQOqVJYWBAR1bHsAgX+tyUW+cUqBDZ1xMLBrcUOiYiI9IRKLeCNH+Jx+0EhvBys8MUIP5iY6Odg7UeJWlgsW7YMXbp0gY2NDVxcXDBs2DBcvnz5scdERUVBIpGUeVy6dKmOoiYiqjqVWsDMH+Jx834BGtlbYvWYzjCT8hoPERGV+L+Iyzh6NQOWZlKsH+cPOyszsUOqNFFbs+joaEyfPh0nTpxAZGQklEolgoKCkJ+f/8RjL1++jNTUVM2jRQvDuEVERPXb8t8u48iVdFiYmWDDeH84WJuLHZJe4oUnIqqPDp1PxZqo6wCAj19sj9butiJHpBtR56s6dOiQ1vNNmzbBxcUFcXFx6NWr12OPdXFxgb29fS1GR0RUs345cwfroksajE9f6oi2HnYiR6S/Si88denSBUqlEgsXLkRQUBASEhJgbf34WVEuX74MW9v/GmNnZ65gTkT679q9XMzeeQYA8NrTPhjaqZHIEelOrybCzc7OBgA4ODg8cV8/Pz8UFRWhTZs2eOedd9C3b99y95PL5ZDL5ZrnOTk5AACFQgGFQqFTfKX763qcvjGGPJiD/jCGPOoih4upuXh7d0mDMaWHNwa1ca7x96tOHvr2+fHCExHVJ7lFCvxvaxzyi1V4yscBYcGtxA6pSvSmsBAEAaGhoejRowfatWtX4X7u7u7YsGED/P39IZfLsXXrVvTv3x9RUVHlNjbLli3DkiVLymyPiIiAlZVVlWKNjIys0nH6xhjyYA76wxjyqK0c8hXAinNSFCkkaGWnRhvlNRw4cK1W3guoWh4FBQW1EEnNqY0LT0RE+kCtFjBn1xncSM+Hm62FQY+905vCYsaMGTh79iz++uuvx+7n6+sLX19fzfPAwEDcunULK1asKLewCAsLQ2hoqOZ5Tk4OPD09ERQUpHWrvDIUCgUiIyMxYMAAmJkZzkCaRxlDHsxBfxhDHrWZg1KlxqQtp5Apz4SXgyXCQ7rBzrJ2fk7VyaP0bq4+qq0LTwDvaj/KGHIAjCMP5qA/ajuPddE38NuFuzCTSvDVyA6wk5kY7B1tvSgsZs6ciZ9//hlHjhxB48aNdT6+W7duCA8PL/c1mUwGmUxWZruZmVmV/4CozrH6xBjyYA76wxjyqI0cPvktAcduZMLKXIqvx3eBk23V7pTqoip56PNnV1sXngDe1a6IMeQAGEcezEF/1EYel7IkWHfRBIAELzRR4s65Y7hzrsbfRqO272iLWlgIgoCZM2di7969iIqKgo+PT5XOEx8fD3d39xqOjoioevadTsE3fyUCAP7v5Y7wdbMROSLDU5sXngDe1X6UMeQAGEcezEF/1FYetx4UYNHafyBAgREBjfDB0LY1du5H1dUdbVELi+nTp2Pbtm3Yt28fbGxskJaWBgCws7ODpaUlgJIv/ZSUFGzZsgUAsHLlSnh7e6Nt27YoLi5GeHg49uzZgz179oiWBxHRo86nZGPenrMAgOl9m2FQe1780EVdXXjiXe3yGUMOgHHkwRz0R03mUViswoztZ5FVqEBHT3ssHdYeZqbSGjn349T2HW1RC4u1a9cCAPr06aO1fdOmTZg4cSIAIDU1FcnJyZrXiouLMWfOHKSkpMDS0hJt27bF/v37ERwcXFdhExE9VmZ+MV7fGocihRp9fJ0ROsD3yQeRFl54IiJjJQgCFu49h4TUHDham2PtmM6Q1UFRURdE7wr1JJs3b9Z6PnfuXMydO7eWIiIiqh6lSo2Z208hJasQ3o5W+GKkH6QmErHDMji88ERExuq7YzfxY3wKpCYSrBrdGR72lmKHVGP0YvA2EZGx+PS3y/j72n1YmUuxflxArc0AZex44YmIjNHJxEx8sP8iACBsUCsENnMUOaKaZZiT5BIR6aGfz9zBhiM3AAArOFibiIgecjenCNO+PwWlWsBzHT0wqUfVxo7pMxYWREQ14GJqDubtLhmsPbVPMwRzsDYREf2rWKnG1PA4ZOTJ4etqg09ebA+JxPi6ybKwICKqpuwCBV7fGodChQo9WzhhThAHaxMR0X/e/zUBp5KzYGNhivXj/GFlbpyjEVhYEBFVg0ot4I0f4pGcWYDGDS3xJQdrExHRQ3bF3sLWE0mQSIAvRnaCt5O12CHVGhYWRETVsPL3K4i+kg4LMxNsGBeAhtbmYodERER64nxKNhb+dB4A8Fb/lujXylXkiGoXCwsioiqKuJCGr/68BgBY9kJ7tPHQbaVmIiIyXqVrGhUr1ejfygUz+zUXO6Rax8KCiKgKrqfnIXTnGQDAxO7eGO7XWOSIiIhIXyhVaryxPR4pWYXwcbLGZyM6waQedJNlYUFEpKN8uRIhW+OQJ1eiq7cDFg5uLXZIRESkR1ZEXMFf1zJgZS7FurH+9WZNIxYWREQ6EAQBc3efxdV7eXC1lWHVGD+YSflVSkREJQ6eS8W66OsAgE9f6lCv1jRia0hEpINvjiZi/7lUmEklWDOmM1xsLMQOiYiI9MTVu7mYs6ukm+yUnj4Y0sFD5IjqFgsLIqJKOn79PpYdvAgAeHdIG/g3cRA5IiIi0hc5RSVrGuUXq9C9mSPmPdtK7JDqHAsLIqJKSM0uxIxtp6AWgBf8GmFctyZih0RERHpCrRYwe+cZ3MjIh4edBb4a5QfTethNtv5lTESko2KlGtO+P4X7+cVo7W6LD4e3h0Ri/LN7EBFR5aw+fA2RCXdhbmqCtWP94dhAJnZIomBhQUT0BB/sT0B8chZsLUyxbmxnWJpLxQ6JiIj0xOHL9/DZ71cAAB8MbYeOnvbiBiQiFhZERI+xN/42thxPAgCsHNkJTRytRY6IiIj0RfL9Ary5PR6CAIx+yguvdPEUOyRRsbAgIqrAxdQchP14DgDwRr/m6NfKVeSIiIhIXxQWq/C/rbHIKVLCz8sei55rI3ZIomNhQURUjuxCBaaGx6FIoUavls5485mWYodERER6QhAEzP/xLC6l5cKpgTnWjvGHzJTdZEUtLJYtW4YuXbrAxsYGLi4uGDZsGC5fvvzE46Kjo+Hv7w8LCws0bdoU69atq4Noiai+EAQBc3adwc37BWhkb4kvRnSC1ISDtYmIqMSmv29i3+k7MDWRYPXoznCz45pGgMiFRXR0NKZPn44TJ04gMjISSqUSQUFByM/Pr/CYxMREBAcHo2fPnoiPj8eCBQvwxhtvYM+ePXUYOREZs3XRN0pm95CaYO3YzmhobS52SEREpCf+uXEfHx4oWdNo4eDWeKqpo8gR6Q9TMd/80KFDWs83bdoEFxcXxMXFoVevXuUes27dOnh5eWHlypUAgNatWyM2NhYrVqzAiy++WNshE5GRO379Ppb/dgkAsPj5tujQ2F7cgIiISG+kZRdh+rZTUKkFDOvkgYndvcUOSa/o1RiL7OxsAICDQ8Wr2R4/fhxBQUFa2wYOHIjY2FgoFIpajY+IjNvdnCLM3F6yCN5L/o0xqmv9nt2DiIj+I1eqMfX7OGTkFaOVmw2WvdCBaxo9QtQ7Fg8TBAGhoaHo0aMH2rVrV+F+aWlpcHXVnpnF1dUVSqUSGRkZcHd313pNLpdDLpdrnufk5AAAFAqFzoVI6f6GXsAYQx7MQX8YQx4KhQIqNfDGD2c0DcZ7wb5QKpVih6aT6nwW+vb5LVu2DD/++CMuXboES0tLdO/eHZ988gl8fX0fe1x0dDRCQ0Nx4cIFeHh4YO7cuQgJCamjqInImH1w4JJmTaMN4wK4plE59KawmDFjBs6ePYu//vrrifs+Wh0KglDudqCkcVqyZEmZ7REREbCysqpSrJGRkVU6Tt8YQx7MQX8Yeh4/J5vgVGo2LKQCXnJ7gMO//yZ2SFVWlc+ioKCgFiKputIxeF26dIFSqcTChQsRFBSEhIQEWFuXv5ZI6Ri8KVOmIDw8HH///TemTZsGZ2dndpUlomo5fleCH27chkQCfDnKD16OVfsb0tjpRWExc+ZM/Pzzzzhy5AgaN2782H3d3NyQlpamte3evXswNTWFo2PZwTNhYWEIDQ3VPM/JyYGnpyeCgoJga2urU5wKhQKRkZEYMGAAzMzMdDpWnxhDHsxBfxhDHgfO3kHU8fMAgM9e8cOANi4iR1Q11fksSu/m6guOwSMifXH2djZ2J5aMHpg9oCX6+BpmG1EXRC0sBEHAzJkzsXfvXkRFRcHHx+eJxwQGBuKXX37R2hYREYGAgIByG1KZTAaZTFZmu5mZWZX/CKrOsfrEGPJgDvrDUPNIzMjHwp9LBmtP7uGN4I6NRI6o+qryWej7Z1edMXgbN26EQqEoN0d2l9VmDDkAxpEHc9AP9/PkmL79NJSCBP18nTDl6SYGmU9ddZUVtbCYPn06tm3bhn379sHGxkZzJ8LOzg6WlpYASu44pKSkYMuWLQCAkJAQrFq1CqGhoZgyZQqOHz+OjRs3Yvv27aLlQUSGqbBYhanhcciTK9HMRsDsZ5qLHRKVo7bG4AHsLlsRY8gBMI48mIN4VAKwNsEEaTkmcLEQEGSbhkOHDoodVrXUdldZUQuLtWvXAgD69OmjtX3Tpk2YOHEiACA1NRXJycma13x8fHDgwAHMmjULq1evhoeHB7788kve5iYinb2377xm1dQJLQtgKtWrifLoX7U1Bg9gd9lHGUMOgHHkwRzE9/Ghy7iakwRLMykm+crx/CDDzAOou66yoneFepLNmzeX2da7d2+cOnWqFiIiovpiZ8wt7Iq7DRMJ8PnLHZB56YTYIVE5anMMHsDushUxhhwA48iDOYjj17N3sPHvJADAJy+0hZB8yiDzeFRtd5Xl5TkiqncS7uTg3X0lg7VnB/miW9OK++2TOARBwIwZM/Djjz/izz//rPQYvEdv8z9uDB4RUXkup+Vi7u6zAICQ3s0wqJ2byBEZDhYWRFSv5BYpMO37OMiVavT1dcbU3s3EDonKMX36dISHh2Pbtm2aMXhpaWkoLCzU7BMWFobx48drnoeEhCApKQmhoaG4ePEivv32W2zcuBFz5swRIwUiMkDZhQqEhMehoFiFp5s7Yk5QS7FDMigsLIio3hAEAfP2nMXN+wVoZG+Jz17pBBMTrpqqj9auXYvs7Gz06dMH7u7umseOHTs0+1Q0Bi8qKgqdOnXC+++/zzF4RFRparWA2TtPIzEjH43sLfHVqM4ce6cjncdYCIKA6OhoHD16FDdv3kRBQQGcnZ3h5+eHZ555Bp6enrURJxFRtX137CYOnEuDmVSCVaP90NDaXOyQqAIcg0dEde2rP6/h94v3YG5qgnVj/eHANkJnlS7DCgsL8dFHH8HT0xODBg3C/v37kZWVBalUimvXrmHRokXw8fFBcHAwTpzgIEgi0i+nb2XhwwMXAQALglvDz6uhyBEREZG++PPSXaz84woA4MNh7dC+sZ3IERmmSt+xaNmyJZ566imsW7cOAwcOLHcgXFJSErZt24YRI0bgnXfewZQpU2o0WCKiqsgqKMb0709BoRIwqJ0bJnb3FjskIiLSEzcz8vHmD6chCMC4bk3wcgB731RVpQuLgwcPPnZhIgBo0qQJwsLCMHv2bCQlJVU7OCKi6hIEAXN2nUFKViGaOFrhk5c6VLimAVVfdnY29u7dW2532YEDB6J79+5ih0hEpFFQrMTrW+OQW6REZy97vDukjdghGbRKd4V6UlHxMHNzc7Ro0aJKARER1aSvj97Q9JldPbozbC047WhtSE1NxZQpU+Du7o6lS5ciPz8fnTp1Qv/+/dG4cWMcPnwYAwYMQJs2bbQGYBMRiaVkQo9zuHw3F842Mqwd6w9zUw7Wro4qLZD37rvvYvHixZBKpVrbs7OzERISgu3bt9dIcERE1RF7MxOfHLoMAFj0XBu0a8Q+s7WlY8eOGD9+PE6ePFnhhajCwkL89NNP+Oyzz3Dr1i1OA0tEotr4VyJ+OXMHpiYSrBnTGa62FmKHZPCqVFhs2bIFkZGR+P7779GsWckc8FFRURg/fjwaNWpUowESEVVFZn4xZm6Ph0ot4PmOHhjd1UvskIzahQsX4Ozs/Nh9LC0tMWrUKIwaNQrp6el1FBkRUVnHr9/HsoOXAADvDmmDLt5cKLUmVOl+z9mzZ+Ht7Y1OnTrh66+/xttvv42goCBMnDgRf/31V03HSESkE7VaQOjO00jNLkJTJ2t89EJ7jquoZU8qKkqVTiNb2f2JiGpaanYhZmw7BZVawAt+jTA+sInYIRmNKhUWdnZ2+OGHH/DGG2/g9ddfxxdffIGDBw9i6dKlZbpHERHVtfVHbiDqcjpkpiZYPaYzGsiqdHOWqmjcuHHIy8srs/3mzZvo1auXCBEREZWQK1UICT+F+/nFaONuiw+H88JTTaryCJWvvvoKn3/+OUaNGoWmTZvijTfewJkzZ2oyNiIincXczMSKiJJxFUueb4vW7rYiR1T/JCQkoH379vj7778127777jt07NgRrq6uIkZGRPXd4p8v4MytLNhbmWH9OH9YmvOCeE2qUmExaNAgLFmyBFu2bMH333+P+Ph49OrVC926dcOnn35a0zESEVVKZn4xZm4rGVcxrJMHRnThXORi+OeffzBixAj069cPCxYswMsvv4wZM2bg888/x+7du8UOj4jqqe0nk7H95C1IJMCXI/3g6WAldkhGp0r9A5RKJc6ePQsPDw8AJQPy1q5diyFDhmDy5MmYO3dujQZJRPQkpeMq0nKK0NTZmre3RWRqaoqPP/4YMpkM77//PkxNTREdHY3AwECxQyOieio++QEW7bsAAJgT5IteLTnOqzZU6Y5FZGSkpqh42ODBg3Hu3LlqB0VEpKsNRx8aVzG6M6w5rkI0CoUCs2fPxieffIKwsDAEBgZi+PDhOHDggNihEVE9lJ4rx9TwUyhWqTGwrSum9WkmdkhGq8ZbXicnJwAlM3/waiER1YW4pEws/61kXMVijqsQXUBAAAoKChAVFYVu3bpBEAR8+umneOGFF/Daa69hzZo1YodIRPWEQqXGjG2nkJZThGbO1ljxckf+fVqLKn3HonXr1ti2bRuKi4sfu9/Vq1cxdepUfPLJJ9UOjojoSR48NK7i+Y4eGMlxFaILCAjA6dOn0a1bNwCARCLBvHnzcOLECRw5ckTk6IioPvn44CX8k5iJBjJTrB8XABsLM7FDMmqVvmOxevVqzJs3D9OnT0dQUBACAgLg4eEBCwsLPHjwAAkJCfjrr7+QkJCAGTNmYNq0abUZNxERBEHA27vP4E52EXy4XoXe2LhxY7nbO3XqhLi4uDqOhojqq32nU7Dxr0QAwIqXO6C5SwORIzJ+lb5j0a9fP8TExGD//v1wc3PDtm3bMGPGDIwZMwaLFy/G1atXMX78eNy+fRsff/wxbG2f3BXhyJEjeO655+Dh4QGJRIKffvrpsftHRUVBIpGUeVy6dKmyaRCREdn4VyJ+v3gP5qYmWDXaj+tViCg/P79S+8lkMp32JyKqioupOZi35ywAYFqfZni2nbvIEdUPOrfC3bt3R/fu3WvkzfPz89GxY0e8+uqrePHFFyt93OXLl7UKF67gSlT/nL6VhU8OlVxUeHdIG7T1sBM5ovqtefPmmDlzJiZOnFju5B5AyR2m33//HZ999hl69eqFsLCwOo6SiOqD7AIFQsLjUKRQo2cLJ8wO8hU7pHpD1Mt7gwYNwqBBg3Q+zsXFBfb29jUfEBEZhOxCBWZuPwWFSkBwezeMfcpL7JDqvaioKLzzzjtYsmQJOnXqVG532ePHj8PMzAxhYWH43//+J3bIRGSE1GoBb+2IR9L9AjRuaIkvR/pBasIusnVFp8Ji6dKl5W63s7ODr68vgoKCYGJS5cW8K83Pzw9FRUVo06YN3nnnHfTt27fCfeVyOeRyueZ5Tk4OgJLpEBUKhU7vW7q/rsfpG2PIgznoj7rOQxAEzN11BrcyC9G4oSXef641lEpltc7Jz6L6ufv6+mLXrl24ffs2du3ahSNHjuDYsWMoLCyEk5MT/Pz88PXXXyM4OLhO2gkiqp9W/nEVh/+denzdWH80tDYXO6R6RafCYu/eveVuz8rKQkpKCtq2bYvffvsNLi4uNRLco9zd3bFhwwb4+/tDLpdj69at6N+/P6KiotCrV69yj1m2bBmWLFlSZntERASsrKq24mJkZGSVjtM3xpAHc9AfdZXH0TQJfkuUQioR8ErjXPx1uObetz5/FgUFBTXy3o0bN8asWbMwa9asGjkfEVFl/Z5wF1/+cRUA8NHw9mjXiF1k65pOhUV8fHyFr6WmpmL06NFYsGABvvnmm2oHVh5fX1/4+v7XTy4wMBC3bt3CihUrKiwswsLCEBoaqnmek5MDT09PBAUFVWqA+cMUCgUiIyMxYMAAmJkZ7nRlxpAHc9AfdZlHQmoO5qz/B4CAec+2wqvdm9TIeflZ/Hc3V58cOXIEy5cvR1xcHFJTU7F3714MGzaswv2joqLKvYN98eJFtGrVqhYjJSKx3UjPw6wdpwEAEwKb4EX/xuIGVE/V2BgLd3d3fPDBBxg3blxNnbJSunXrhvDw8Apfl8lkmllIHmZmZlblPyCqc6w+MYY8mIP+qO088uRKzNp5DgqVgP6tXDClV7Man1q2Pn8WNZH3a6+9Vu720u6yY8eORYMGlZ/ukRN8EFFl5MuVeH1rHHLlSgQ0aYiFg9uIHVK9VaODtxs1aoR79+7V5CmfKD4+Hu7unEKMyJgJgoB39p7DjYx8uNtZcOVUPfXgwYNytycmJuL777/H+++/j6NHj6Jp06aVOh8n+CCiJxEEAXN3n8XVe3lwsZFhzZjOMDflOC6x1GhhcebMGXh7e1d6/7y8PFy7dk3zPDExEadPn4aDgwO8vLwQFhaGlJQUbNmyBQCwcuVKeHt7o23btiguLkZ4eDj27NmDPXv21GQaRKRndsXdxk+n70BqIsGXo/w4GE9PVTQODwAKCwsxfvx4zJ8/Hzt37qzVOHSZ4IOIDNvXR29g/7lUmEklWDu2M1xsLcQOqV7TqbCoqA9udnY2YmJiMHv2bEyePLnS54uNjdX6wi8dCzFhwgRs3rwZqampSE5O1rxeXFyMOXPmICUlBZaWlmjbti3279+P4OBgXdIgIgNy9W4uFu27AAAIHdASXbwdRI6IqsLS0hLz5s3DCy+8UGvvUZUJPjhzoDZjyAEwjjyYw5Mdv3EfHx8sWc9o4SBfdPCwqZX3qu+fhS7H6FRY2NvbV9j9QCKR4PXXX8fcuXMrfb4+ffpAEIQKX9+8ebPW87lz5+p0fiIybEUKFWZsi0ehQoWeLZwwtXczsUOianBwcEBWVlatnb8qE3xw5sDyGUMOgHHkwRzKlykHVpyVQi1I0NVZDfuM8zhw4HyNv8/D6utnocusgToVFocPHy53u62tLVq0aAGZTIbU1FR4eXGxKiKqviW/JODy3Vw4NZDhs1c6wYSLHBm0Y8eOoVmzui0OnzTBB2cO1GYMOQDGkQdzqJhcocKojTHIV+agrYcNNk7uCgszaY2d/1H1/bPQZdZAnQqL3r17P/b1M2fOoHPnzlCpVLqcloiojF/P3sH2k8mQSICVIzrB2abs7G6kX86ePVvu9tLush999BE++OCDOo3pSRN8cObA8hlDDoBx5MEctAmCgAU/JeBcSg4aWplh/bgA2FjVzbiK+vpZ6LJ/jQ7eJiKqCcn3CxC25xwAYFqfZujRwknkiKgyOnXqBIlEUm4XV2dnZ8ybNw8hISGVPh8n+CCiR207mYxdcbdhIgG+GtUZjRtWrcsi1Q4WFkSkV4qVaszcfkozH/msZ1qKHRJVUmJiYrnb7ezsYG9vj/z8fBw5cqTC8Q6P4gQfRPSwuKQHWPxzyWQebw9sxYtOeoiFBRHplU8PXcKZ29mwszTDF6P8YCrlfOSGokmTx6+Efu3aNfTt27fS3WU5wQcRlbqXW4Rp38dBoRIwqJ0bQnpXbj0cqls6FRYV9Z8tdfny5WoFQ0T12x8X7+Kbv0quei9/qQMa2VuKHBEREYlNoVJjxvfxuJsjR3OXBljORVL1lk6FxeP6z5Zu5wdNRFWRml2I2bvOAAAmdvdGUFs3kSMiIiJ98OH+izh5MxMNZKZYP84fDWTscKOvdPpkKuo/S0RUHUqVGm9uP42sAgXaNbJFWHArsUMiIiI9sDf+NjYfuwkA+L9XOqKZcwNxA6LH0qmweFL/WSKiqvjyj6uaq1GrRnWGzLT25iOn2vPzzz8/9nVenCIiXVy4k42wH0tmCJzZrzkG8k623tOpsPj0008xc+ZMWFqW9Hs+cuQInnrqKc0c4Lm5uZg3bx7WrFlT85ESkVE6di0DXx0umVL0w+Ht4O1kLXJEVFXDhg174j7sLktElZFVUIyQ8DgUKdTo3dIZb3GGQIOg03QrYWFhyM3N1TwfMmQIUlJSNM8LCgqwfv36mouOiIxaRp4cb+44DUEARnbxxNBOjcQOiapBrVY/8cEFVInoSVRqAW/+cBq3Mgvh5WCFL0Z2gtSEFyUMgU6FxaODth83DSAR0eOo1QJCd55Beq4cLV0bYNFzbcUOiYiI9MDnkVcQfSUdFmYmWDfWH/ZW5mKHRJXECeKJSBTrj9zAkX8bjlWjO8PSnOMqjMnWrVvx9NNPw8PDA0lJSQCAzz//HPv27RM5MiLSZ79dSMOqf7vHfvxCB7TxsBU5ItIFCwsiqnNxSZlYEVGy7s2S59uipauNyBFRTVq7di1CQ0MRHByMrKwsTfenhg0bYuXKleIGR0R663p6HmbvLJl2/NWnvTHMj91jDY3OEwF/8803aNCgZKovpVKJzZs3w8mpZEn1h8dfEBGVJ6ugGG9sPw2VWsDQTh54JcBT7JCohn311Vf4+uuvMWzYMHz88cea7QEBAZgzZ46IkRGRvsqTK/H61jjkyZXo6uOABcGtxQ6JqkCnwsLLywtff/215rmbmxu2bt1aZh8iovIIgoC3d59FSlYhvB2t8OHw9pwlyAglJibCz8+vzHaZTIb8/HwRIiIifSYIAt7edQbX7uXB1VaGVaP9YCZlpxpDpFNhcfPmzVoKg4jqg01/30Rkwl2YS0vGVXD1VOPk4+OD06dPl1n76ODBg2jdmlchiUjbuugbOHg+DWZSCdaO9YeLjYXYIVEV6dSqFxUV4ffff8eQIUMAlEw/K5fL/zuZqSmWLl0KCwv+QhCRtjO3srDs4EUAwMLBrdGukZ3IEVFtefvttzF9+nQUFRVBEAScPHkS27dvx0cffYSNGzeKHR4R6ZGjV9Ox/LdLAIDFz7dFZ6+GIkdE1aFTYfHdd9/h119/1RQWq1atQtu2bTUL5l26dAlubm4IDQ2t+UiJyGBlFyowY/spKFQCnm3rhvGBTZ58EBmsV199FUqlEnPnzkVBQQFGjx6NRo0a4auvvkLPnj3FDo+I9MStzAK8sT0eagF4JaAxRndld3pDp1MHtu+//x6vvfaa1rZt27bh8OHDOHz4MJYvX45du3ZV+nxHjhzBc889Bw8PD0gkEvz0009PPCY6Ohr+/v6wsLBA06ZNsW7dOl1SIKI6JggC5u85i1uZhfB0sMQnL3XguIp6YMqUKUhKSsK9e/eQlpaGkydPIj4+Hs2bNxc7NCLSA0UKFULC4/CgQIEOje2wdGg7tg1GQKfC4sqVK2jZ8r8l1S0sLGBi8t8punbtioSEhEqfLz8/Hx07dsSqVasqtX9iYiKCg4PRs2dPxMfHY8GCBXjjjTewZ8+eyidBRHVq64kkTd/ZVaM6w87STOyQqJZkZWVhzJgxcHZ2hoeHB7788ks4ODhg9erVaN68OU6cOIFvv/1W7DCJSGSCIGDB3nO4cCcHDtbmWDvWHxZmXMvIGOjUFSo7Oxumpv8dkp6ervW6Wq3WGnPxJIMGDcKgQYMqvf+6devg5eWlmQe9devWiI2NxYoVK/Diiy9W+jxEVDfO3c7GB7+WjKuYP6g1OnraixsQ1aoFCxbgyJEjmDBhAg4dOoRZs2bh0KFDKCoqwoEDB9C7d2+xQyQiPRB+Igk/nkqBiQRYNcoPjewtxQ6JaohOhUXjxo1x/vx5+Pr6lvv62bNn0bhx4xoJrDzHjx9HUFCQ1raBAwdi48aNUCgUMDMreyVULpdrFTs5OTkAAIVCAYVCodP7l+6v63H6xhjyYA76o6I8cosUmPZ9HIpVagxo7YJxXRvpba7G/lnocmx17N+/H5s2bcIzzzyDadOmoXnz5mjZsiUXxSMijbikTCz5paR3y7xnW6F7cyeRI6KapFNhERwcjPfeew+DBw8uM/NTYWEhlixZgsGDB9dogA9LS0uDq6ur1jZXV1colUpkZGTA3d29zDHLli3DkiVLymyPiIiAlZVVleKIjIys0nH6xhjyYA764+E8BAHYfMUEtx6YwEEmoF+DOzh48I6I0VWOMX4WlVVQUFDt971z5w7atGkDAGjatCksLCwwefLkap+XiIzDvZwiTA0/BaVawOAO7vhfr6Zih0Q1TKfCYsGCBdi5cyd8fX0xY8YMtGzZEhKJBJcuXcKqVaugVCqxYMGC2ooVAMoM7BEEodztpcLCwrRmqcrJyYGnpyeCgoJga2ur03srFApERkZiwIAB5d4dMRTGkAdz0B/l5bHlRDJOZ16CmVSCDROfQsfG+j21rDF/FpVVeje3OtRqtdb7SqVSWFtbV/u8RGT4ipVqTPv+FO7lytHStQE+fZETeRgjnQoLV1dXHDt2DFOnTsX8+fO1/qgfMGAA1qxZU+aOQk1yc3NDWlqa1rZ79+7B1NQUjo6O5R4jk8kgk8nKbDczM6vyHxDVOVafGEMezEF/lOZx5lYWPj50GQAQNqg1AnwM5za3sX0Wuh5TXYIgYOLEiZrv3KKiIoSEhJQpLn788cdKne/IkSNYvnw54uLikJqair1792LYsGGPPSY6OhqhoaG4cOECPDw8MHfuXISEhFQpHyKqOR8duIjYpAewkZli/bgAWHOBVKOk86fq4+ODQ4cOITMzE9euXQMANG/eHA4ODjUe3KMCAwPxyy+/aG2LiIhAQECAUfwxQGTosgsUmPb9f+tVvPq0t9ghUR2aMGGC1vOxY8dW63ylMwe++uqrlZqgo3TmwClTpiA8PBx///03pk2bBmdnZ07wQSSin07fweZjNwEAn4/oBB8n3sk0VlUuFx0cHNC1a9dqvXleXp6mOAFKGoXTp0/DwcEBXl5eCAsLQ0pKCrZs2QIACAkJwapVqxAaGoopU6bg+PHj2LhxI7Zv316tOIio+gRBwJzdZ5GSVQgvByt8+jJvc9c3mzZtqtHzceZAIsN3Ox/4cl/JYO03+7fAM21qr2cLiU+ndSxqWmxsLPz8/ODn5wcACA0NhZ+fH9577z0AQGpqKpKTkzX7+/j44MCBA4iKikKnTp3w/vvv48svv2SDQaQHNv6dhMiEuzCXmmDNmM6wteBdRKpbFc0cGBsba/AzfhEZogcFxdh4WQq5Uo2+vs54s38LsUOiWiZqB7c+ffpoxmmUZ/PmzWW29e7dG6dOnarFqIhIV9dzgNX/XAUAvPdcG7RrpN+Dtck4VWXmQE5Jrs0YcgCMIw9Dz0GlFvDWjjPIlEvg2dASy19sB5VKCZVK7Mh0Z+ifBVB305Fz5AwRVUtGnhybr0ihUgsY7tcIY57yEjskqsd0nTmQU5KXzxhyAIwjD0PN4ZdkExxLMYG5iYDRnrn4+7Bh5vEwQ/0sHlbb05GzsCCiKlOpBYTuOocchQQtXKzx4fB2HFdBoqnKzIGcklybMeQAGEcehpxDRMJd/H78DABgVDM1JgwzvBweZsifRam6mo6chQURVdn/RVzG8RuZMDcR8NXITrAy51cKiacqMwdySvLyGUMOgHHkYWg5XLuXi7l7zgMAXuveBB2F6waXQ0WMIY/ano5c1MHbRGS4IhPuYk3UdQAlV6SaOXP6QKpZeXl5OH36NE6fPg3gv5kDSyf1CAsLw/jx4zX7h4SEICkpCaGhobh48SK+/fZbbNy4EXPmzBEjfKJ6J7dIgf9tjUN+sQrdmjrg7SAO1q5veHmRiHSWdD8foTtPAwAmBHqhM26IGxAZpdjYWPTt21fzvLTL0oQJE7B58+YKZw6cNWsWVq9eDQ8PD84cSFRH1GoBs3eewY30fLjZWmDV6M4wlfL6dX3DwoKIdFJYrEJI+CnkFinh36Qh5ga1xO8RLCyo5nHmQCLDsTb6OiL+nXJ87djOcGogM+hZlKhqWEoSUaUJgoCFe8/hYmoOnBqYY/XozjA35dcIEVF9Fn0lHSsiLgMAlgxtCz+vhiJHRGLhXwREVGlbjifhx/gUSE0k+GpUZ7jZWYgdEhERiehWZgHe2B4PQQBGdfXEqK6ccrw+Y2FBRJVyMjET7/+aAAAIG9QKgc3Kn76TiIjqh8JiFf63NQ7ZhQp0bGyHxc+3FTskEhkLCyJ6orTsIkz7/hSUagFDOrhjUg8fsUMiIiIRCYKAsB/P4mJqDhytzbF2rD9kplKxwyKRsbAgoscqUqjwengcMvLk8HW1wScvduAieERE9dx3x27ip9N3SrrGjvaDh72l2CGRHmBhQUQVEgQB7+07jzO3smBrYYoN4/1hLeNkckRE9dnJxEx8sP8igJKusd2bOYkcEekLFhZEVKHwE0nYGXsbJhLgq9Gd0cSRi+AREdVnd3P+6xr7XEcPdo0lLSwsiKhcJ27cx5JfSgZrz3u2FXq3dBY5IiIiElOxUo2pWl1j27NrLGlhYUFEZdzKLMDU8DjNFan/9WoqdkhERCSy939NwKnkkq6x68f5w8qcXWNJGwsLItKSJ1diypZYPChQoH0jO3zKwdpERPXerthb2HoiCRIJ8MVIP3g7sWsslcXCgog01GoBoTtO41JaLpxtZNgw3h+W5pw+kIioPjufko2FP50HALzVvyX6tnIROSLSVywsiEhjRcRlRCTchbnUBOvH+cPdjtMHEhHVZ5n5xXh9axyKlWr0b+WCmf2aix0S6THRC4s1a9bAx8cHFhYW8Pf3x9GjRyvcNyoqChKJpMzj0qVLdRgxkXHaHXcba6KuAwA+frE9Ons1FDkiIiISk1Klxsztp5CSVQgfJ2t8PrITTEzYNZYqJmphsWPHDrz11ltYuHAh4uPj0bNnTwwaNAjJycmPPe7y5ctITU3VPFq0aFFHERMZp5OJmQj78SwAYEbf5nihc2ORIyIiIrEtj7iMv6/dh5W5FOvG+sPWwkzskEjPiVpYfPbZZ5g0aRImT56M1q1bY+XKlfD09MTatWsfe5yLiwvc3Nw0D6mUfcCJqupmRj5e3xoLhUpAcHs3hA5oKXZIREQksv1nU7E++gYA4NOXOsDXzUbkiMgQiFZYFBcXIy4uDkFBQVrbg4KCcOzYscce6+fnB3d3d/Tv3x+HDx+uzTCJjFpmfjEmbjqJBwUKdGhsh/97mbe5iYjquyt3c/H27jMAgP/1aoohHTxEjogMhWgTEGdkZEClUsHV1VVru6urK9LS0so9xt3dHRs2bIC/vz/kcjm2bt2K/v37IyoqCr169Sr3GLlcDrlcrnmek5MDAFAoFFAoFDrFXLq/rsfpG2PIgzlUn1yhwpTv4nDzfgEa2Vtg3ehOMJWooVCodTqP2HnUBGPIAaheHoaeOxHVjJwiBV7fGoeCYhW6N3PE3IG+YodEBkT0lU0enR9fEIQK58z39fWFr+9/v+CBgYG4desWVqxYUWFhsWzZMixZsqTM9oiICFhZWVUp5sjIyCodp2+MIQ/mUDVqAdhy1QTx901gKRUwvkkeYo7+Ua1z8rPQH1XJo6CgoBYiISJDUjLl+BkkZuTDw84CX43yg6lU9Hl+yICIVlg4OTlBKpWWuTtx7969MncxHqdbt24IDw+v8PWwsDCEhoZqnufk5MDT0xNBQUGwtbXVKWaFQoHIyEgMGDAAZmaGO4DJGPJgDtWz7OBlxN9PgplUgvXj/RHY1LHK5+JnoT+qk0fp3Vwiqr9WH76G3y/ehbmpCdaN84djA5nYIZGBEa2wMDc3h7+/PyIjIzF8+HDN9sjISAwdOrTS54mPj4e7u3uFr8tkMshkZf9hmJmZVfkPiOocq0+MIQ/moLsNR67j22NJAEoG5PXydauR8/Kz0B9VycMY8iaiqjt8+R4++/0KAOCDoe3QobG9uAGRQRK1K1RoaCjGjRuHgIAABAYGYsOGDUhOTkZISAiAkrsNKSkp2LJlCwBg5cqV8Pb2Rtu2bVFcXIzw8HDs2bMHe/bsETMNIoOxN/42PjpQsu7LguBWGO7HaWWJiOq7pPv5eHN7PAQBGP2UF17p4il2SGSgRO04N2LECKxcuRJLly5Fp06dcOTIERw4cABNmjQBAKSmpmqtaVFcXIw5c+agQ4cO6NmzJ/766y/s378fL7zwglgpEBmMw5fu4e1dJWtVTOrhgyk9m4ocEdGTcRFVotpVUKzE61vjkFOkhJ+XPRY910bskMiAiT54e9q0aZg2bVq5r23evFnr+dy5czF37tw6iIrIuJxMzERIeByUagHPd/TAwuDWFU6SQKQvShdRXbNmDZ5++mmsX78egwYNQkJCAry8vCo87vLly1pj6JydnesiXCKDIwgCwn48h0tpuXBqYI61Y/whM+XaYFR1HOpPZOTOp2Rj0uYYyJVq9Gvlgv97pSPXqiCDwEVUiWrXpr9vYt/pO5CaSLB6dGe42VmIHRIZONHvWBBR7bl2LxcTvj2JXLkSXb0dsHp0Z5hx6kAyAKWLqM6fP19re2UXUS0qKkKbNm3wzjvvoG/fvhXuy7WOtBlDDoBx5FHbOfyTmIkPD1wEAMwb2BKdPW1r/L2M4XMAjCOPulrniIUFkZFKzMjH6K//wf38YrT1sMU3EwNgac4rt2QY6moRVa51VD5jyAEwjjxqI4csObD8nBQqtQT+Tmq4PLiAAwcu1Pj7lDKGzwEwjjxqe50jFhZERuhWZgFGf30C93LlaOVmg62TnoKtBacTJcNT24uocq0jbcaQA2AcedRWDnKlGmM2xiBPkY1WbjbYNKVrrV10MobPATCOPOpqnSMWFkRG5lZmAUZ9fQKp2UVo5myN8MlPwcHaXOywiHRSV4uocq2j8hlDDoBx5FHTOSz69RzO3M6GrYUpNowLgK117Y+rMIbPATCOPGp7nSN2tiYyIsn3CzBywwncflAIb0crbJvSDU5cOZUM0MOLqD4sMjIS3bt3r/R5nrSIKlF9siMmGdv+SYZEAnwxyg9ejlXr7kdUEd6xIDISJWMqSu5UNHWyxrYp3eBqyxk+yHBxEVWimnPmVhbe3VcyjmL2gJbo6+sickRkjFhYEBmBK3dzMfabf3AvV47mLg2wbcpTcLFhUUGGbcSIEbh//z6WLl2K1NRUtGvXrlKLqKakpMDS0hJt27bF/v37ERwcLFYKRHohI0+OqeFxKFaqMaCNK6b1aS52SGSkWFgQGbgzt7IwYdNJZBUo4Otqg++nPMXuT2Q0uIgqUfUoVWrM3BaPO//ezeZaRlSbWFgQGbBj1zMw5btY5Ber0MnTHptf7QJ7Kw7UJiKiEp/+dhnHb9yHlbkU68f5c4ZAqlUsLIgM1K9n7yB0xxkUq9R4urkjNowLgLWM/6SJiKjEr2fvYMORGwCAFS93RAtXG5EjImPHv0KIDIwgCPjmaKJmxdRn27ph5chOsDDj4ndERFTiclou5u4+CwAI6d0Mwe05OxrVPhYWRAZEqVLjg/0XsfnYTQDAxO7eeHdIG0jZX5aIiP6VXajA61tjUVCsQo/mTpgT1FLskKieYGFBZCCyCxWYuT0eR66kAwDeGdwak3r4VLgKMRER1T9qtYDQHadx834BGtlb4stRfjCVctkyqhssLIgMQGJGPiZ9F4Mb6fmwMDPBZ6904m1tIiIq48s/r+KPS/dgbmqCdWP94WDNCT2o7rCwINJzf1y8i1k7TiOnSAl3Owt8PT4A7RrZiR0WERHpmT8v3cXK368CAD4a3h7tG7OtoLrFwoJIT6nUAj6LvIzVh68DAPy87LF+nD8XviMiojJuZuTjzR9OAwDGdWuCl/wbixsQ1UssLIj00N2cIszacRrHrt8HUDJIe0Fwa5ibsp8sERFpKyhW4vWtccgtUsK/SUO8O6SN2CFRPcXCgkjPRCbcxdzdZ/CgQAErcyk+frEDnu/oIXZYRESkhwRBwNzdZ3H5bi6cbWRYM6YzL0KRaET/zVuzZg18fHxgYWEBf39/HD169LH7R0dHw9/fHxYWFmjatCnWrVtXR5ES1a48uRIL957DlC2xeFCgQFsPW/w8oweLCiIiqtDGvxLx69lUmJpIsGZMZ7jasrssiUfUwmLHjh146623sHDhQsTHx6Nnz54YNGgQkpOTy90/MTERwcHB6NmzJ+Lj47FgwQK88cYb2LNnTx1HTlSzjl5Nx8DPj+D7f0p+91/v1RQ/TuuO5i4NRI6MiIj01bHrGVh28BKAkinIu3g7iBwR1XeidoX67LPPMGnSJEyePBkAsHLlSvz2229Yu3Ytli1bVmb/devWwcvLCytXrgQAtG7dGrGxsVixYgVefPHFugydqEbkKYCwvRew+1QKAKBxQ0t8+mIHdG/uJHJkRESkz+5kFWLmtnio1AJe8GuECd29xQ6JSLzCori4GHFxcZg/f77W9qCgIBw7dqzcY44fP46goCCtbQMHDsTGjRuhUChgZmZW5hi5XA65XK55npOTAwBQKBRQKBQ6xbw26hribprg9IGLMDc1hdREAlMTCUyl/z5MTGAmlcBM+vB/TWBuagJzqQlkpv89LMykkJmZwMJUCkuzkn3qaqGz0rx1zV+fGHoOKrWA7SeTsPy0FAXKkqJiXDcvzH6mOaxlpgaVl6F/FoBx5ABULw9Dz52oPilSqDA1PA7384vRxt0WH73Qnoulkl4QrbDIyMiASqWCq6ur1nZXV1ekpaWVe0xaWlq5+yuVSmRkZMDdveyCYcuWLcOSJUvKbI+IiICVlZVOMW8/I0VqgQmiU2/pdFxlSCDA3ASQSQFzKSD79/9lUgEWUsBCClhKAQtTAZZSwNIUsDIFrEwFWJkC1v8+N9HheyUyMrLG86hrhpjDlWwJ9iWZ4Ha+BIAEHlYCXvZRoankBqL/uCF2eFVmiJ/Fo4whB6BqeRQUFNRCJERUGxb/fAFnbmfD3soM68f5w8JMKnZIRAD0YFaoRytsQRAeW3WXt39520uFhYUhNDRU8zwnJweenp4ICgqCra2tTrGm2SYi5txleDVpAkFiAqVKDaVaKHmo1FCoSv5foVJDqSr5b7FKjWJlyUP+0KNIqUKRQg2VuiR+ARLI1YBcDUDrwmHlKwWJBLCzMIODtRkcrM3haG0OxwbmcLKWwcnGHM4NZHC2kcHRUor4E0fwbNCAcu/yGAKFQoHIyEgMGGA4OSSk5mBFxFUcvVYyhWwDmRQD3YuxaGw/WMpkIkdXdYb4WTzKGHIAqpdH6d1cItJv208m44eYW5BIgC9G+sHTQbeLpES1SbTCwsnJCVKptMzdiXv37pW5K1HKzc2t3P1NTU3h6OhY7jEymQyycv5oMzMz07nhfa2HD9xyLiI4uHWN/fGhUKlRqFChqFiFgmIV8ouVKPz3//PkSuTJlciXK5FbpERukQK5RUrkFCmQU6hEdqECWYXFyCoo2S4IQFahAlmFCtzIePzVRwmk+OTCMbjZW8Ld1gLu9hZoZG9Z8mhoicYNrdDQykzvb61W5XOsa2duZeGrP6/h94t3AQBmUgnGPNUEIT2b4J8jf8BSJtP7HCrDED6LJzGGHICq5WEMeRMZu/jkB1i07wIAYE6QL3q3dBY5IiJtohUW5ubm8Pf3R2RkJIYPH67ZHhkZiaFDh5Z7TGBgIH755RetbREREQgICDDYRrF0HIatRfXiV6jUyCpQ4EFBMTLzi3E/rxj38+XIyCtGeq7830cR7ubIkZ4nh0oN3M2V426uHGcqOKeVuRSeDa3g6WAFLwcreDlYoomTNbwdrdG4oSXMpKLPVqy31GoBhy/fw+ZjN3H0agaAkjtKQzp4YE5QSzRxtGafdiIiqrT0XDmmhp9CsUqNgW1dMa1PM7FDIipD1K5QoaGhGDduHAICAhAYGIgNGzYgOTkZISEhAEq6MaWkpGDLli0AgJCQEKxatQqhoaGYMmUKjh8/jo0bN2L79u1ipqEXzKQmcLYp6er0JEXyYuz6+SDadnka6flKpGUX4U5WIVJKHw8KcS9XjoJiFS7fzcXlu7llziE1kaBxQ0t4O1rDx8kaTZ1L/uvjZA0PO0uY6DLYw4ik58rxU3wKwv9JQtL9krtGUhMJhnVqhGl9m6GZM6ePJSIi3ShUaszYdgppOUVo5myNFS931PseBVQ/iVpYjBgxAvfv38fSpUuRmpqKdu3a4cCBA2jSpAkAIDU1VWtNCx8fHxw4cACzZs3C6tWr4eHhgS+//JJTzepIaiKBrTnQvpFdhXd6ihQqpGQV4vaDQiRnFiD5fj6S7hcgObMAN+/no0ihRtL9AiTdL0D0lXStYy3MTODtaI1mzg3QzNkazVwaoKlTAzR1toa1TPRhPTUuT67E4Uv38FN8CqKupGvGzdhamGJkVy+M69aEfWCJiKjKPj54Cf8kZsLaXIr14/xhU81eDkS1RfS/8qZNm4Zp06aV+9rmzZvLbOvduzdOnTpVy1GRhZn038Kg7BV2tVrAvVw5EjPycfN+Pm5m5ONGRj5upOchObMARQo1LqXl4lJa2TsdbrYWaOpcUnQ0dbZGU+cGaOpkDQ97S0gN6C7HrcwC/HUtA78n3MXRaxkoVqo1r3XytMcrAZ4Y5ucBK3PR/4kRGbQ1a9Zg+fLlSE1NRdu2bbFy5Ur07Nmzwv2jo6MRGhqKCxcuwMPDA3PnztXcBScyRL+cTcXGvxIBAP/3Sic0d7EROSKiivGvHtKZiYkEbnYWcLOzQGAz7UHzSpUatx8U4kZGHm6k5+N6eh6u3Sv5//v5xUjLKUJaThGOXb+vdZy51ARNHK3QxNEaPk5W8HK0RpN/x3Z42FvC3FS88RxqtYBr6XmIT36A+OQsHL9xX9PNqZS3oxWC27vjhc6NuVo2UQ3ZsWMH3nrrLaxZswZPP/001q9fj0GDBiEhIQFeXl5l9k9MTERwcDCmTJmC8PBw/P3335g2bRqcnZ15Z5sMUmIusP6nksHa0/o0w7Pt3ESOiOjxWFhQjTKVmsDbyRreTtbo10r7tewCBa6l5+FGep7mDkdiRj5uZhSgWKXG1Xt5uHovr8w5JRLA1cYCjRqWzFrlbmcBpwZmSLkvgdPNTLjZW8PR2hw2FmZVvutRrFQjM78Yqdkl3b9uPSjAjfR8XLmbi6t381CoUGntLzWRwM/THr1aOmNgWze0dG3A/q5ENeyzzz7DpEmTMHnyZADAypUr8dtvv2Ht2rVYtmxZmf3XrVsHLy8vrFy5EgDQunVrxMbGYsWKFSwsyKDky5VYfugSvjsvhQA1erZwwuwgX7HDInoiFhZUZ+yszODfpCH8mzTU2q5SC0h5UIib9/ORdD8fiRkFSM7MLxnb8W/XqtI7HXFJDx46UorNV2I1zyQSwNbCDDYWprAyl8LK3BQy05JZt0ylEkgAKNUCVGoBcqUa+XIlCopVyCooRk6R8rGxW5pJ0aGxHfy8GiKgSUM81dSBfVyJalFxcTHi4uIwf/58re1BQUE4duxYucccP34cQUFBWtsGDhyIjRs3QqFQlDumTC6XQy6Xa56XruehUCh0mrktPjkLa6KuIz3DBHsz4iAxoK6dDxPUgsHnABh+HhdTc5GWIwcgwZD2rljyXBuoVUqoVU88VK+U/hsy9FkQjSGP6uSgyzEsLEh0UhMJvByt4OVoBUB7Tm5BEJCRV/zvQPICpGUXITW7CHceFOBychrU5tbIyCtGnrxkHY/sQgWyC6v2D19qIoFzAxk8HUrW8WjiaAVfVxu0dLNBEwcrmHJ6XaI6k5GRAZVKVWZdI1dX1zLrGZVKS0srd3+lUomMjAy4u7uXOWbZsmVYsmRJme0RERGwsqr8pAtn7ksQdVUKwAR4cP+J++s3Y8gBMPQ8HGQCXvFRo3WDFPx1OEXscKolMjJS7BBqhDHkUZUcCgoevzbaw1hYkF6TSCSaaXQ7edprtisUChw4kILg4B4wMzNDsVL9b1FRjNyikkUG8+RKFP+7CrpSLUAtCDA1kUBqIoG51ATWMlNYy0xhZ2kKR2sZ7CzN6u00uUT66tEuhoIgPLbbYXn7l7e9VFhYGEJDQzXPc3Jy4OnpiaCgINja2lY6zg4PCuFzNR0JCRfQpk1bSKXSSh+rT1QqlcHnABh+HlbmUvRoao+/o//EgAEDDHatLoVCgcjISIPOATCOPKqTQ+md3MpgYUFGwdy08ut4EJH+c3JyglQqLXN34t69e2XuSpRyc3Mrd39TU1M4OjqWe4xMJoNMVvZ7Q9fVy31czNC4oSUOZJxHcFcvg/7jw9BzAIwjj9LuJ7r+LuojY8gBMI48qpKDLvuzbwcREekdc3Nz+Pv7l7ltHxkZie7du5d7TGBgYJn9IyIiEBAQYPB/DBARGQIWFkREpJdCQ0PxzTff4Ntvv8XFixcxa9YsJCcna9alCAsLw/jx4zX7h4SEICkpCaGhobh48SK+/fZbbNy4EXPmzBErBSKieoVdoYiISC+NGDEC9+/fx9KlS5Gamop27drhwIEDaNKkCQAgNTUVycnJmv19fHxw4MABzJo1C6tXr4aHhwe+/PJLTjVLRFRHWFgQEZHemjZtGqZNm1bua5s3by6zrXfv3jh16lQtR0VEROVhVygiIiIiIqo2FhZERERERFRt9a4rVOmc5rrMyVtKoVCgoKAAOTk5Bj3DiDHkwRz0hzHkYQw5ANXLo/Q7sfQ7sr6q722EMeQAGEcezEF/GEMeddU+1LvCIjc3FwDg6ekpciRERPonNzcXdnZ2YochGrYRRETlq0z7IBHq2eUptVqNO3fuwMbG5rGrt5andEXWW7du6bQiq74xhjyYg/4whjyMIQegenkIgoDc3Fx4eHjAxKT+9pKt722EMeQAGEcezEF/GEMeddU+1Ls7FiYmJmjcuHG1zmFra2uwv1gPM4Y8mIP+MIY8jCEHoOp51Oc7FaXYRpQwhhwA48iDOegPY8ijttuH+ntZioiIiIiIagwLCyIiIiIiqjYWFjqQyWRYtGgRZDKZ2KFUizHkwRz0hzHkYQw5AMaTh6Eyhp+/MeQAGEcezEF/GEMedZVDvRu8TURERERENY93LIiIiIiIqNpYWBARERERUbWxsCAiIiIiompjYVFFzz//PLy8vGBhYQF3d3eMGzcOd+7cETssndy8eROTJk2Cj48PLC0t0axZMyxatAjFxcVih6aTDz/8EN27d4eVlRXs7e3FDqfS1qxZAx8fH1hYWMDf3x9Hjx4VOySdHDlyBM899xw8PDwgkUjw008/iR2SzpYtW4YuXbrAxsYGLi4uGDZsGC5fvix2WDpZu3YtOnTooJmbPDAwEAcPHhQ7rHrP0NsIY2kfAMNsI9g+iM8Y2geg7tsIFhZV1LdvX+zcuROXL1/Gnj17cP36dbz00ktih6WTS5cuQa1WY/369bhw4QI+//xzrFu3DgsWLBA7NJ0UFxfj5ZdfxtSpU8UOpdJ27NiBt956CwsXLkR8fDx69uyJQYMGITk5WezQKi0/Px8dO3bEqlWrxA6lyqKjozF9+nScOHECkZGRUCqVCAoKQn5+vtihVVrjxo3x8ccfIzY2FrGxsejXrx+GDh2KCxcuiB1avWbobYSxtA+A4bURbB/0gzG0D4AIbYRANWLfvn2CRCIRiouLxQ6lWj799FPBx8dH7DCqZNOmTYKdnZ3YYVRK165dhZCQEK1trVq1EubPny9SRNUDQNi7d6/YYVTbvXv3BABCdHS02KFUS8OGDYVvvvlG7DDoIcbQRhhy+yAIhtNGsH3QT8bSPghC7bYRvGNRAzIzM/H999+je/fuMDMzEzucasnOzoaDg4PYYRi14uJixMXFISgoSGt7UFAQjh07JlJUBJT8/gMw2H8DKpUKP/zwA/Lz8xEYGCh2OPQvY2kj2D7UPrYP+svQ2wegbtoIFhbVMG/ePFhbW8PR0RHJycnYt2+f2CFVy/Xr1/HVV18hJCRE7FCMWkZGBlQqFVxdXbW2u7q6Ii0tTaSoSBAEhIaGokePHmjXrp3Y4ejk3LlzaNCgAWQyGUJCQrB37160adNG7LDqPWNqI9g+1A22D/rJkNsHoG7bCBYWD1m8eDEkEsljH7GxsZr93377bcTHxyMiIgJSqRTjx4+HoAfrDeqaBwDcuXMHzz77LF5++WVMnjxZpMj/U5UcDI1EItF6LghCmW1Ud2bMmIGzZ89i+/btYoeiM19fX5w+fRonTpzA1KlTMWHCBCQkJIgdltExhjbCGNoHwPjbCLYP+sWQ2wegbtsI01o5q4GaMWMGRo4c+dh9vL29Nf/v5OQEJycntGzZEq1bt4anpydOnDghehcEXfO4c+cO+vbti8DAQGzYsKGWo6scXXMwJE5OTpBKpWWuPt27d6/MVSqqGzNnzsTPP/+MI0eOoHHjxmKHozNzc3M0b94cABAQEICYmBh88cUXWL9+vciRGRdjaCOMoX0AjLeNYPugfwy9fQDqto1gYfGQ0kagKkqvQsnl8poMqUp0ySMlJQV9+/aFv78/Nm3aBBMT/biJVZ3PQt+Zm5vD398fkZGRGD58uGZ7ZGQkhg4dKmJk9Y8gCJg5cyb27t2LqKgo+Pj4iB1SjRAEQS++i4yNMbQRxtA+AMbbRrB90B/G2j4AtdtGsLCogpMnT+LkyZPo0aMHGjZsiBs3buC9995Ds2bNRL9boYs7d+6gT58+8PLywooVK5Cenq55zc3NTcTIdJOcnIzMzEwkJydDpVLh9OnTAIDmzZujQYMG4gZXgdDQUIwbNw4BAQGaK4HJyckG1X85Ly8P165d0zxPTEzE6dOn4eDgAC8vLxEjq7zp06dj27Zt2LdvH2xsbDRXCe3s7GBpaSlydJWzYMECDBo0CJ6ensjNzcUPP/yAqKgoHDp0SOzQ6i1jaCOMpX0ADK+NYPugH4yhfQBEaCNqZa4pI3f27Fmhb9++goODgyCTyQRvb28hJCREuH37ttih6WTTpk0CgHIfhmTChAnl5nD48GGxQ3us1atXC02aNBHMzc2Fzp07G9wUdocPHy735z5hwgSxQ6u0in7/N23aJHZolfbaa69pfo+cnZ2F/v37CxEREWKHVa8ZQxthLO2DIBhmG8H2QXzG0D4IQt23ERJB0IPRxkREREREZND0p8MkEREREREZLBYWRERERERUbSwsiIiIiIio2lhYEBERERFRtbGwICIiIiKiamNhQURERERE1cbCgoiIiIiIqo2FBRERERERVRsLCyIiIiIiqjYWFkREREREVG0sLIiIiIiIqNpYWBDVsfT0dLi5ueGjjz7SbPvnn39gbm6OiIgIESMjIiIxsX0gQycRBEEQOwii+ubAgQMYNmwYjh07hlatWsHPzw+DBw/GypUrxQ6NiIhExPaBDBkLCyKRTJ8+Hb///ju6dOmCM2fOICYmBhYWFmKHRUREImP7QIaKhQWRSAoLC9GuXTvcunULsbGx6NChg9ghERGRHmD7QIaKYyyIRHLjxg3cuXMHarUaSUlJYodDRER6gu0DGSresSASQXFxMbp27YpOnTqhVatW+Oyzz3Du3Dm4urqKHRoREYmI7QMZMhYWRCJ4++23sXv3bpw5cwYNGjRA3759YWNjg19//VXs0IiISERsH8iQsSsUUR2LiorCypUrsXXrVtja2sLExARbt27FX3/9hbVr14odHhERiYTtAxk63rEgIiIiIqJq4x0LIiIiIiKqNhYWRERERERUbSwsiIiIiIio2lhYEBERERFRtbGwICIiIiKiamNhQURERERE1cbCgoiIiIiIqo2FBRERERERVRsLCyIiIiIiqjYWFkREREREVG0sLIiIiIiIqNpYWBARERERUbX9P8km2M6NP7MAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "# Some sample data\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "Vq1tiGaryJ3p"
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkiBpu3eyQXC",
    "outputId": "c4434cae-6a67-4d53-a198-9e243cc908f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(GPT_CONFIG_124M[\"emb_dim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jnu0Ew5QyYOD",
    "outputId": "aebb96c2-ebfd-434b-bed2-fb2d62cc99c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "\n",
    "# input shape: [batch_size, num_token, emb_size]\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AE6e3JwTzgTn"
   },
   "source": [
    "## Adding shortcut connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "7nmbM3Y3zcNQ"
   },
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # Compute the output of the current layer\n",
    "            layer_output = layer(x)\n",
    "            # Check if shortcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x\n",
    "\n",
    "\n",
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # Calculate loss based on how close the target\n",
    "    # and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "\n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4J6y_yBo1Yq-",
    "outputId": "1c9bec98-2db0-4a91-b8e9-bdda41aa89ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041653171182\n",
      "layers.3.0.weight has gradient mean of 0.001398873864673078\n",
      "layers.4.0.weight has gradient mean of 0.005049646366387606\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=False\n",
    ")\n",
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQBMX-KN1Zbf",
    "outputId": "9304f945-a9c6-4d0d-9902-da6179d82325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.2216978669166565\n",
      "layers.1.0.weight has gradient mean of 0.20694100856781006\n",
      "layers.2.0.weight has gradient mean of 0.3289698660373688\n",
      "layers.3.0.weight has gradient mean of 0.2665731906890869\n",
      "layers.4.0.weight has gradient mean of 1.3258538246154785\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXhkttEE1oq2"
   },
   "source": [
    "## Connecting attention and linear layers in transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "X77s27Wv1mq8"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IBiMezXd6hYV",
    "outputId": "47c71413-2870-4746-a085-e2224a35e5f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "x = torch.rand(2, 4, 768)  # Shape: [batch_size, num_tokens, emb_dim]\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZczLAywA6nnc"
   },
   "source": [
    "## Coding GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "UniSBru76ky9"
   },
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s_SHAfIz8H_o",
    "outputId": "f717d65c-477d-4983-9a8a-f7f0aaf7fb75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.1381,  0.0077, -0.1963,  ..., -0.0222, -0.1060,  0.1717],\n",
      "         [ 0.3865, -0.8408, -0.6564,  ..., -0.5163,  0.2369, -0.3357],\n",
      "         [ 0.6989, -0.1829, -0.1631,  ...,  0.1472, -0.6504, -0.0056],\n",
      "         [-0.4290,  0.1669, -0.1258,  ...,  1.1579,  0.5303, -0.5549]],\n",
      "\n",
      "        [[ 0.1094, -0.2894, -0.1467,  ..., -0.0557,  0.2911, -0.2824],\n",
      "         [ 0.0882, -0.3552, -0.3527,  ...,  1.2930,  0.0053,  0.1898],\n",
      "         [ 0.6091,  0.4702, -0.4094,  ...,  0.7688,  0.3787, -0.1974],\n",
      "         [-0.0612, -0.0737,  0.4751,  ...,  1.2463, -0.3834,  0.0609]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yqysJNtQ8h4w",
    "outputId": "74a0ca4e-d1ff-4e8c-e5f5-92625a01a9be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 50257])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-pIcH4oa8lHR",
    "outputId": "4863d652-6194-4856-d37e-867b62e5b486"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m_DqskND8qZU",
    "outputId": "d1b013bb-83cb-4958-ef0b-9b07a5d58ff1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VAkjWVoS9Bj-",
    "outputId": "583e32f9-c885-46f7-d7b5-9d5e8d8d109d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19y8X1d7_nx5",
    "outputId": "70e97a67-85af-4df2-85c0-eaa559edab4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 =  total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W500z08p_0YI"
   },
   "source": [
    "## Generating Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G764o88SjTHX"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "Vxi9NOxK_4GQ"
   },
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBXSKyRyLof1",
    "outputId": "76c7da2d-9511-406e-b2b2-fc066dba6995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dM0amwl-L1Bd",
    "outputId": "9a19c742-515c-4409-f78a-866af06b9346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TyK3lqSAL_3x",
    "outputId": "f5cee6fe-03f6-4fe6-f6af-082d2634b305"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,    11,   314,   716]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C5kVhthZMC8X",
    "outputId": "f0567a9e-9c70-41ac-ad9d-a10ca203a1fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval() # disable dropout\n",
    "\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor,\n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JV_WXq81NgYh",
    "outputId": "e0db03e5-e832-40aa-e49c-d5d732c70079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1KGjM31jWG9"
   },
   "source": [
    "# Step 5: Pretraining on unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J2MRw4o-jVyE",
    "outputId": "a601f5fe-eade-4ec1-9dae-8d749fc1cd83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.1\n",
      "numpy version: 2.0.2\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.6.0\n",
      "tensorflow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "QiONSP_zjwy5"
   },
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lb5-UWXGkKkd",
    "outputId": "5ee4dff2-1133-4d37-ced8-2539c68e9689"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasn refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1TsGRttnXU-"
   },
   "source": [
    "## Calculating text generation loss: cross-entropy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "6sujEzjhnSLr"
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0yXMENzoc8G",
    "outputId": "39b3aa50-de42-48a3-e4d5-b96b5cd22db0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f0Ac2PKWpdAP",
    "outputId": "514e8682-efc7-4953-dbf0-6077a97ea620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5BOzsMluq-4w",
    "outputId": "3cba2ab8-0f09-44d4-ed14-63dddbc7d9b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ke0XhfyHrEZG",
    "outputId": "82fa9291-204c-448a-966c-a0fea6903dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([    0.0001,     0.0000,     0.0000])\n",
      "Text 2: tensor([    0.0000,     0.0001,     0.0000])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cMvoTy_orKPw",
    "outputId": "903033fe-ac57-42f9-b500-66abcd2cce9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pkTGeiIzrwLq",
    "outputId": "e00e6cfb-a949-4fa5-b6e8-6645f660d2a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2vB-I2qOr_Eb",
    "outputId": "109cdba1-decf-4df1-c710-4d662093ada0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nWEaFZebs14m",
    "outputId": "d72a64ae-9cab-4752-dbc1-ab6c0c74f8a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64d4YtpAttOI",
    "outputId": "ad4f4375-85c3-4ccd-ff06-1af0b04e1869"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kKKQMEeStxl0",
    "outputId": "3813c4ce-e3b9-44d6-fe92-e0b5a812f46f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RQ9rzeOt3iJ",
    "outputId": "95b711fd-c256-497d-bed0-ba5404721d50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmn1nT3Pt7Fu"
   },
   "source": [
    "## Calculating training and validation set loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "U3d2MyvZuBH3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-5CR3Ng5uLVZ",
    "outputId": "31e4cb18-12cc-4ea9-945d-7b2591fc194f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# First 100 characters\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2CYGkoiuc9o",
    "outputId": "5de3ffd3-7262-423d-f82a-71d14e430504"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# Last 100 characters\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bF8QaT6eudT3",
    "outputId": "25b508b1-c81e-47a8-838b-00b73b95d5f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "YpkbhFoGuds4"
   },
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "KjmMWYZPueFB"
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_Hsjcr5wDMs",
    "outputId": "ef943572-ed5a-44b8-8dd0-eccd657d2e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QL7StaeRyGP4",
    "outputId": "fe2cabe6-ad07-4f37-dd8b-f166092f32d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "svrHxULVyLtZ"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plUoaHtRyQqT",
    "outputId": "b3bbbfd2-a39d-4d0f-c111-1a39f3973d5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n",
      "Training loss: 10.98758347829183\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#\n",
    "print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwwrcUC518Py"
   },
   "source": [
    "## Training an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "LGFdmMuaz5Wf"
   },
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzRtzZaU6DHJ",
    "outputId": "751fa104-0b4c-4f21-8592-0abbbe0d1077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.783, Val loss 9.927\n",
      "Ep 1 (Step 000005): Train loss 7.985, Val loss 8.335\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.753, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 6.114, Val loss 6.573\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,,,,, and,,,, and,, and,,,,, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.525, Val loss 6.490\n",
      "Ep 3 (Step 000025): Train loss 5.324, Val loss 6.387\n",
      "Every effort moves you, and to the picture.                      \"I, and the of the of the's the honour, and, and I had been, and I\n",
      "Ep 4 (Step 000030): Train loss 4.761, Val loss 6.360\n",
      "Ep 4 (Step 000035): Train loss 4.461, Val loss 6.258\n",
      "Every effort moves you of the to the picture--as of the picture--as I had been \" it was his \" I was the     \"I was his I had been the his pictures--and it the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 3.833, Val loss 6.196\n",
      "Every effort moves you know the \"Oh, and he was not the fact by his last word.         \"I was.      \"Oh, I felt a little a little the    \n",
      "Ep 6 (Step 000045): Train loss 3.352, Val loss 6.139\n",
      "Ep 6 (Step 000050): Train loss 2.861, Val loss 6.112\n",
      "Every effort moves you know; and my dear, and he was not the fact with a little of the house of the fact of the fact, and.                       \n",
      "Ep 7 (Step 000055): Train loss 2.347, Val loss 6.138\n",
      "Ep 7 (Step 000060): Train loss 2.084, Val loss 6.179\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I looked--as of the fact, and I felt him--his back his head to the donkey. \"Oh, and_--because he had always _\n",
      "Ep 8 (Step 000065): Train loss 1.521, Val loss 6.176\n",
      "Ep 8 (Step 000070): Train loss 1.272, Val loss 6.178\n",
      "Every effort moves you?\" \"I didn't bear the picture--I told me.  \"I looked up, and went on groping and Mrs. I was back the head to look up at the honour being _mine_--because he was when I\n",
      "Ep 9 (Step 000075): Train loss 1.000, Val loss 6.277\n",
      "Ep 9 (Step 000080): Train loss 0.718, Val loss 6.281\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.506, Val loss 6.325\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to the donkey again. I saw that, and down the room, when I\n",
      "Training completed in 24.65 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "nPqFt_6K6n3s",
    "outputId": "08a0d04d-ade7-4b2f-db00-1501d0e0c42c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMWpny4_6zVt"
   },
   "source": [
    "## Decoding strategies to minimize randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rGNQoImk6uUo",
    "outputId": "3039e91b-c1e7-4da4-f226-8dd1ad466636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KP6N3jyh6-xa"
   },
   "source": [
    "Temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nKjBSCm7A89",
    "outputId": "1f860c38-efe5-41c7-90d0-e5d972ecd883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# Suppose input is \"every effort moves you\", and the LLM\n",
    "# returns the following logits for the next token:\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# The next generated token is then as follows:\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8swJd887Nr5",
    "outputId": "d388e031-daff-4fd0-df0b-8752e023a8a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WiItj0gR7Pgs",
    "outputId": "c348d963-cde9-4acd-ea0c-98f3d6b4caf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "d4xCYz8W7U2S"
   },
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "B0LkUODy7ejK",
    "outputId": "53320b14-bada-44f0-fe31-6fe5bbaa0a43"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6HizfQv7rZM",
    "outputId": "d371f5b3-9cfc-493a-fbb2-1abf4752f810"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "992 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "8 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccEFvLK27sQO",
    "outputId": "d31520ec-47c7-4ec8-eb9a-b80b65406adf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 x closer\n",
      "68 x every\n",
      "55 x effort\n",
      "223 x forward\n",
      "102 x inches\n",
      "50 x moves\n",
      "43 x pizza\n",
      "218 x toward\n",
      "88 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7FRGXgn7zI4"
   },
   "source": [
    "## Top-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uu6cNRtZ7vX0",
    "outputId": "8346013d-4cea-4b82-b5fb-8d931d0b31b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-iw8rqp8C4c",
    "outputId": "09023ea5-9e69-4b27-9bcd-5ddbd4c23243"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float(\"-inf\")),\n",
    "    other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJ5XC9dr8Exu",
    "outputId": "009e23b2-0e4e-425f-d205-c726b61abac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-ZBBexE8IxY"
   },
   "source": [
    "## Modifying our text generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "_QNGJiq58NsO"
   },
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X73pidrx-9e5",
    "outputId": "ac6b1fa2-d80b-4257-e43b-bb549fe901ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to my surprise, a little it was the\n",
      "\"Ah enough\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d4zyFee_F_u"
   },
   "source": [
    "## Loading and saving model weights in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "UlplfwBt_DFi"
   },
   "outputs": [],
   "source": [
    "#to save:\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "cFE1O7l0IAxc"
   },
   "outputs": [],
   "source": [
    "#to load model weights to new gpt\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iShtGVFAIzJ4"
   },
   "source": [
    "Loading pretrained weights from Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-m9OY0XbyhwQ",
    "outputId": "49750383-aa16-4535-d400-f0458f5f67c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (2.18.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tqdm in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.8.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\alexa\\onedrive\\documents\\modernai\\llm\\.pixi\\envs\\default\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "ziOVhSuaIOUU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def download_and_load_gpt2(model_size, models_dir):\n",
    "    # Validate model size\n",
    "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
    "    if model_size not in allowed_sizes:\n",
    "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
    "\n",
    "    # Define paths\n",
    "    model_dir = os.path.join(models_dir, model_size)\n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "    backup_base_url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\"\n",
    "    filenames = [\n",
    "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
    "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
    "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
    "    ]\n",
    "\n",
    "    # Download files\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    for filename in filenames:\n",
    "        file_url = os.path.join(base_url, model_size, filename)\n",
    "        backup_url = os.path.join(backup_base_url, model_size, filename)\n",
    "        file_path = os.path.join(model_dir, filename)\n",
    "        download_file(file_url, file_path, backup_url)\n",
    "\n",
    "    # Load settings and params\n",
    "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\"), \"r\", encoding=\"utf-8\"))\n",
    "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "\n",
    "    return settings, params\n",
    "\n",
    "\n",
    "def download_file(url, destination, backup_url=None):\n",
    "    def _attempt_download(download_url):\n",
    "        with urllib.request.urlopen(download_url) as response:\n",
    "            # Get the total file size from headers, defaulting to 0 if not present\n",
    "            file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "\n",
    "            # Check if file exists and has the same size\n",
    "            if os.path.exists(destination):\n",
    "                file_size_local = os.path.getsize(destination)\n",
    "                if file_size == file_size_local:\n",
    "                    print(f\"File already exists and is up-to-date: {destination}\")\n",
    "                    return True  # Indicate success without re-downloading\n",
    "\n",
    "            block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "            # Initialize the progress bar with total file size\n",
    "            progress_bar_description = os.path.basename(download_url)\n",
    "            with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "                with open(destination, \"wb\") as file:\n",
    "                    while True:\n",
    "                        chunk = response.read(block_size)\n",
    "                        if not chunk:\n",
    "                            break\n",
    "                        file.write(chunk)\n",
    "                        progress_bar.update(len(chunk))\n",
    "            return True\n",
    "\n",
    "    try:\n",
    "        if _attempt_download(url):\n",
    "            return\n",
    "    except (urllib.error.HTTPError, urllib.error.URLError):\n",
    "        if backup_url is not None:\n",
    "            print(f\"Primary URL ({url}) failed. Attempting backup URL: {backup_url}\")\n",
    "            try:\n",
    "                if _attempt_download(backup_url):\n",
    "                    return\n",
    "            except urllib.error.HTTPError:\n",
    "                pass\n",
    "\n",
    "        # If we reach here, both attempts have failed\n",
    "        error_message = (\n",
    "            f\"Failed to download from both primary URL ({url})\"\n",
    "            f\"{' and backup URL (' + backup_url + ')' if backup_url else ''}.\"\n",
    "            \"\\nCheck your internet connection or the file availability.\\n\"\n",
    "            \"For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\"\n",
    "        )\n",
    "        print(error_message)\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Alternative way using `requests`\n",
    "\"\"\"\n",
    "def download_file(url, destination):\n",
    "    # Send a GET request to download the file in streaming mode\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Get the total file size from headers, defaulting to 0 if not present\n",
    "    file_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "    # Check if file exists and has the same size\n",
    "    if os.path.exists(destination):\n",
    "        file_size_local = os.path.getsize(destination)\n",
    "        if file_size == file_size_local:\n",
    "            print(f\"File already exists and is up-to-date: {destination}\")\n",
    "            return\n",
    "\n",
    "    # Define the block size for reading the file\n",
    "    block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "    # Initialize the progress bar with total file size\n",
    "    progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
    "    with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "        # Open the destination file in binary write mode\n",
    "        with open(destination, \"wb\") as file:\n",
    "            # Iterate over the file data in chunks\n",
    "            for chunk in response.iter_content(block_size):\n",
    "                progress_bar.update(len(chunk))  # Update progress bar\n",
    "                file.write(chunk)  # Write the chunk to the file\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJkZM9nzO_Z3",
    "outputId": "6a1d5d4f-8ea3-4311-b8df-09aa520cae94"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|| 77.0/77.0 [00:00<00:00, 8.98kiB/s]\n",
      "encoder.json: 100%|| 1.04M/1.04M [00:00<00:00, 1.77MiB/s]\n",
      "hparams.json: 100%|| 90.0/90.0 [00:00<00:00, 12.9kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|| 498M/498M [00:21<00:00, 23.5MiB/s]\n",
      "model.ckpt.index: 100%|| 5.21k/5.21k [00:00<00:00, 810kiB/s]\n",
      "model.ckpt.meta: 100%|| 471k/471k [00:00<00:00, 1.17MiB/s]\n",
      "vocab.bpe: 100%|| 456k/456k [00:00<00:00, 1.11MiB/s]\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ae4H4gnX1bby",
    "outputId": "c39ad5c6-0731-4b7e-c2cb-eacc3de6a9c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r03bX4B21fcG",
    "outputId": "6b21cbcc-7d3f-4c32-cc79-a82891bcbd44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSufb6o81lN7",
    "outputId": "4a7e96ba-50d5-47e1-ad78-8e3b5ed27d9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "a_nHW53D1t6C"
   },
   "outputs": [],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "w7UrtMNT10Dz"
   },
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "7B5J_Qub19cR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n",
    "\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eMJJJILB2HSS",
    "outputId": "94e601bc-cedd-42eb-9049-9180f8b184d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward an equal share for each vote plus half. Inequality is often not an accurate representation of human worth; to know the\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvL77eyJ2Owx"
   },
   "source": [
    "# Step 6: Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "DlxJqjip6DfD"
   },
   "outputs": [],
   "source": [
    "#to save:\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
